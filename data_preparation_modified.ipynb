{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_data = pd.read_csv('leaderboard_data.csv')\n",
    "racecourse_data = pd.read_csv('race_course_data.csv')\n",
    "rider_season_data = pd.read_csv('rider_season_data.csv')\n",
    "rider_data = pd.read_csv('rider_data.csv')\n",
    "\n",
    "# # changing time to gaps in seconds\n",
    "# def convert_to_seconds(time):\n",
    "#     time = time.split(':')\n",
    "#     if len(time) < 2:\n",
    "#         return -1\n",
    "#     elif len(time) > 2:\n",
    "#         return 0\n",
    "#     return int(time[0])*60 + int(time[1])\n",
    "\n",
    "# leaderboard_data['time'] = leaderboard_data['time'].apply(convert_to_seconds)\n",
    "\n",
    "# drop date from racecourse data\n",
    "racecourse_data = racecourse_data.drop(columns=['date', 'year', 'name', 'stage'])\n",
    "\n",
    "# merge the data based on url, add the course data to the leaderboard data\n",
    "leaderboard_course_merged = pd.merge(leaderboard_data, racecourse_data, on='url', how='inner', validate='many_to_one')\n",
    "\n",
    "rider_data = rider_data.rename(columns={'url': 'rider_url', 'name': 'rider_name'})\n",
    "\n",
    "def standardize_name(name):\n",
    "    name = name.split()\n",
    "    name.sort()\n",
    "    return ' '.join(name)\n",
    "\n",
    "rider_data['merge_name'] = rider_data['rider_name'].str.lower().apply(standardize_name)\n",
    "leaderboard_course_merged['merge_name'] = leaderboard_course_merged['rider'].str.lower().apply(standardize_name)\n",
    "\n",
    "\n",
    "# merge the data based on rider name, add the rider data to the leaderboard data\n",
    "leaderboard_course_rider_merged = pd.merge(leaderboard_course_merged, rider_data, on='merge_name', how='inner', validate='many_to_one')\n",
    "leaderboard_course_rider_merged = leaderboard_course_rider_merged.drop(columns=['rider', 'merge_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess merged data to make number columns ready for training\n",
    "merged_data = leaderboard_course_rider_merged.copy()\n",
    "\n",
    "# change rank to a number\n",
    "def convert_rank(rank):\n",
    "    try:\n",
    "        return int(rank)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "merged_data['rank'] = leaderboard_course_rider_merged['rank'].apply(convert_rank)\n",
    "\n",
    "# change distance to a number\n",
    "def convert_distance(distance):\n",
    "    distance = distance.split()\n",
    "    return float(distance[0])\n",
    "    \n",
    "merged_data['distance'] = leaderboard_course_rider_merged['distance'].apply(convert_distance)\n",
    "\n",
    "# change speed to a number\n",
    "def convert_speed(speed):\n",
    "    speed = speed.split()\n",
    "    if len(speed) < 2:\n",
    "        return None\n",
    "    return float(speed[0])\n",
    "\n",
    "merged_data['speed'] = leaderboard_course_rider_merged['speed'].apply(convert_speed)\n",
    "\n",
    "#change weight to a number\n",
    "def convert_weight(weight):\n",
    "    if isinstance(weight, float):\n",
    "        return weight\n",
    "    weight = weight.split()\n",
    "    return float(weight[0])\n",
    "\n",
    "merged_data['weight'] = leaderboard_course_rider_merged['weight'].apply(convert_weight)\n",
    "\n",
    "# change height to a number\n",
    "def convert_height(height):\n",
    "    if isinstance(height, float):\n",
    "        return height\n",
    "    height = height.split()\n",
    "    return float(height[0])\n",
    "\n",
    "merged_data['height'] = leaderboard_course_rider_merged['height'].apply(convert_height)\n",
    "\n",
    "def merge_name_stage(row):\n",
    "    return row['name'] + ' ' + row['stage']\n",
    "\n",
    "# change ranking to a number\n",
    "def convert_ranking(ranking):\n",
    "    try:\n",
    "        return int(ranking)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "merged_data['ranking'] = leaderboard_course_rider_merged['ranking'].apply(convert_ranking)\n",
    "\n",
    "merged_data['name'] = merged_data.apply(merge_name_stage, axis=1)\n",
    "merged_data = merged_data.drop(columns=['rider_url', 'url', 'stage', 'time', 'won'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of riders: 207\n",
      "Data preprocessing completed and saved.\n"
     ]
    }
   ],
   "source": [
    "# Define feature groups\n",
    "race_numerical = [\n",
    "    'distance', 'vertical_meters', 'speed', 'year', 'score', 'quality', 'ranking'\n",
    "]\n",
    "race_categorical = ['name']\n",
    "rider_numerical = [\n",
    "    'weight', 'height', 'one_day', 'gc', 'tt', 'sprint',\n",
    "    'climber', 'hills', 'age'\n",
    "]\n",
    "rider_categorical_low = ['speciality']\n",
    "rider_categorical_high = ['nationality', 'team', 'rider_name']\n",
    "\n",
    "# Split data into training and testing sets based on 'year'\n",
    "train_data = merged_data[merged_data['year'] < 2024]\n",
    "test_data = merged_data[merged_data['year'] == 2024]\n",
    "\n",
    "# Determine the maximum number of riders across all races in both training and testing data\n",
    "max_riders_train = train_data.groupby(['name', 'year']).size().max()\n",
    "max_riders_test = test_data.groupby(['name', 'year']).size().max()\n",
    "max_riders = max(max_riders_train, max_riders_test)\n",
    "print(f\"Maximum number of riders: {max_riders}\")\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "race_numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "race_categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('onehot', OneHotEncoder(\n",
    "        drop='first', sparse_output=False, handle_unknown='ignore'\n",
    "    ))\n",
    "])\n",
    "\n",
    "rider_numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "rider_categorical_low_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(\n",
    "        strategy='constant', fill_value='Unknown')),\n",
    "    ('onehot', OneHotEncoder(\n",
    "        drop='first', sparse_output=False, handle_unknown='ignore'\n",
    "    ))\n",
    "])\n",
    "\n",
    "rider_categorical_high_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(\n",
    "        strategy='constant', fill_value='Unknown')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Fit pipelines on training data\n",
    "race_numeric_pipeline.fit(train_data[race_numerical])\n",
    "race_categorical_pipeline.fit(train_data[race_categorical])\n",
    "rider_numeric_pipeline.fit(train_data[rider_numerical])\n",
    "rider_categorical_low_pipeline.fit(train_data[rider_categorical_low])\n",
    "rider_categorical_high_pipeline.fit(train_data[rider_categorical_high])\n",
    "\n",
    "# Initialize lists for training data\n",
    "races_train = []\n",
    "targets_train = []\n",
    "rider_names_train = []\n",
    "\n",
    "for (race_name, year), group in train_data.groupby(['name', 'year']):\n",
    "    try:\n",
    "        # Extract race-level features\n",
    "        race_num_data = group[race_numerical].iloc[[0]]\n",
    "        race_cat_data = group[race_categorical].iloc[[0]]\n",
    "\n",
    "        # Extract rider-level features\n",
    "        rider_num_data = group[rider_numerical]\n",
    "        rider_cat_data_low = group[rider_categorical_low]\n",
    "        rider_cat_data_high = group[rider_categorical_high]\n",
    "\n",
    "        # Transform features using fitted pipelines\n",
    "        race_num_processed = race_numeric_pipeline.transform(race_num_data)\n",
    "        race_cat_processed = race_categorical_pipeline.transform(race_cat_data)\n",
    "        rider_num_processed = rider_numeric_pipeline.transform(rider_num_data)\n",
    "        rider_cat_low_processed = rider_categorical_low_pipeline.transform(rider_cat_data_low)\n",
    "        rider_cat_high_processed = rider_categorical_high_pipeline.transform(rider_cat_data_high)\n",
    "\n",
    "        # Combine features\n",
    "        race_features = np.hstack((race_num_processed, race_cat_processed))\n",
    "        rider_features = np.hstack((rider_num_processed, rider_cat_low_processed, rider_cat_high_processed))\n",
    "\n",
    "        # Pad or truncate rider_features to max_riders\n",
    "        n_riders = rider_features.shape[0]\n",
    "        if n_riders < max_riders:\n",
    "            pad_width = max_riders - n_riders\n",
    "            padded_rider_features = np.pad(\n",
    "                rider_features,\n",
    "                ((0, pad_width), (0, 0)),\n",
    "                mode='constant',\n",
    "                constant_values=0\n",
    "            )\n",
    "        else:\n",
    "            padded_rider_features = rider_features[:max_riders, :]\n",
    "\n",
    "        # Create feature matrix by repeating race_features and concatenating with rider_features\n",
    "        feature_matrix = np.hstack((\n",
    "            np.tile(race_features, (max_riders, 1)),\n",
    "            padded_rider_features\n",
    "        ))\n",
    "\n",
    "        # Calculate probabilities for first 3 riders and pad or truncate to max_riders\n",
    "        ranks = group['rank'].values\n",
    "        padded_probabilities = np.zeros(max_riders)\n",
    "        probabilities = np.array([np.exp(-ranks[:3]) / np.sum(np.exp(-ranks[:3]))])\n",
    "        padded_probabilities[0:3] = probabilities\n",
    "\n",
    "        # Collect rider names and pad or truncate to max_riders\n",
    "        riders = group['rider_name'].tolist()\n",
    "        if n_riders < max_riders:\n",
    "            padded_riders = riders + ['PAD'] * (max_riders - n_riders)\n",
    "        else:\n",
    "            padded_riders = riders[:max_riders]\n",
    "\n",
    "        # Append data to lists\n",
    "        races_train.append(feature_matrix)\n",
    "        targets_train.append(padded_probabilities)\n",
    "        rider_names_train.append(padded_riders)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing race {race_name} {year}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Initialize lists for test data\n",
    "races_test = []\n",
    "targets_test = []\n",
    "rider_names_test = []\n",
    "\n",
    "for (race_name, year), group in test_data.groupby(['name', 'year']):\n",
    "    try:\n",
    "        # Extract race-level features\n",
    "        race_num_data = group[race_numerical].iloc[[0]]\n",
    "        race_cat_data = group[race_categorical].iloc[[0]]\n",
    "\n",
    "        # Extract rider-level features\n",
    "        rider_num_data = group[rider_numerical]\n",
    "        rider_cat_data_low = group[rider_categorical_low]\n",
    "        rider_cat_data_high = group[rider_categorical_high]\n",
    "\n",
    "        # Transform features using pipelines fitted on training data\n",
    "        race_num_processed = race_numeric_pipeline.transform(race_num_data)\n",
    "        race_cat_processed = race_categorical_pipeline.transform(race_cat_data)\n",
    "        rider_num_processed = rider_numeric_pipeline.transform(rider_num_data)\n",
    "        rider_cat_low_processed = rider_categorical_low_pipeline.transform(rider_cat_data_low)\n",
    "        rider_cat_high_processed = rider_categorical_high_pipeline.transform(rider_cat_data_high)\n",
    "\n",
    "        # Combine features\n",
    "        race_features = np.hstack((race_num_processed, race_cat_processed))\n",
    "        rider_features = np.hstack((rider_num_processed, rider_cat_low_processed, rider_cat_high_processed))\n",
    "\n",
    "        # Pad or truncate rider_features to max_riders\n",
    "        n_riders = rider_features.shape[0]\n",
    "        if n_riders < max_riders:\n",
    "            pad_width = max_riders - n_riders\n",
    "            padded_rider_features = np.pad(\n",
    "                rider_features,\n",
    "                ((0, pad_width), (0, 0)),\n",
    "                mode='constant',\n",
    "                constant_values=0\n",
    "            )\n",
    "        else:\n",
    "            padded_rider_features = rider_features[:max_riders, :]\n",
    "\n",
    "        # Create feature matrix by repeating race_features and concatenating with rider_features\n",
    "        feature_matrix = np.hstack((\n",
    "            np.tile(race_features, (max_riders, 1)),\n",
    "            padded_rider_features\n",
    "        ))\n",
    "\n",
    "        # Calculate probabilities and pad or truncate to max_riders\n",
    "        ranks = group['rank'].values\n",
    "        padded_probabilities = np.zeros(max_riders)\n",
    "        probabilities = np.array([np.exp(-ranks[:3]) / np.sum(np.exp(-ranks[:3]))])\n",
    "        padded_probabilities[0:3] = probabilities\n",
    "\n",
    "        # Collect rider names and pad or truncate to max_riders\n",
    "        riders = group['rider_name'].tolist()\n",
    "        if n_riders < max_riders:\n",
    "            padded_riders = riders + ['PAD'] * (max_riders - n_riders)\n",
    "        else:\n",
    "            padded_riders = riders[:max_riders]\n",
    "\n",
    "        # Append data to lists\n",
    "        races_test.append(feature_matrix)\n",
    "        targets_test.append(padded_probabilities)\n",
    "        rider_names_test.append(padded_riders)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing race {race_name} {year}: {e}\")\n",
    "        continue\n",
    "# Find maximum number of riders across all data\n",
    "max_riders = max(\n",
    "    max(len(riders) for riders in rider_names_train),\n",
    "    max(len(riders) for riders in rider_names_test)\n",
    ")\n",
    "\n",
    "def pad_riders(rider_list, max_riders, pad_value='Unknown'):\n",
    "    if len(rider_list) < max_riders:\n",
    "        return rider_list + [pad_value] * (max_riders - len(rider_list))\n",
    "    else:\n",
    "        return rider_list[:max_riders]\n",
    "    \n",
    "# # Pad rider names to max_riders\n",
    "# rider_names_train = [pad_riders(riders, max_riders) for riders in rider_names_train]\n",
    "# rider_names_test = [pad_riders(riders, max_riders) for riders in rider_names_test]\n",
    "\n",
    "# # Initialize lists for padded training data\n",
    "# races_train_padded = []\n",
    "# targets_train_padded = []\n",
    "\n",
    "# for features, targets in zip(races_train, targets_train):\n",
    "#     n_riders = features.shape[0]\n",
    "#     if n_riders < max_riders:\n",
    "#         pad_width = max_riders - n_riders\n",
    "#         padded_features = np.pad(features, ((0, pad_width), (0, 0)), mode='constant', constant_values=0)\n",
    "#         padded_targets = np.pad(targets, (0, pad_width), mode='constant', constant_values=0)\n",
    "#     else:\n",
    "#         padded_features = features[:max_riders, :]\n",
    "#         padded_targets = targets[:max_riders]\n",
    "#     races_train_padded.append(padded_features)\n",
    "#     targets_train_padded.append(padded_targets)\n",
    "\n",
    "# # Initialize lists for padded testing data\n",
    "# races_test_padded = []\n",
    "# targets_test_padded = []\n",
    "\n",
    "# for features, targets in zip(races_test, targets_test):\n",
    "#     n_riders = features.shape[0]\n",
    "#     if n_riders < max_riders:\n",
    "#         pad_width = max_riders - n_riders\n",
    "#         padded_features = np.pad(features, ((0, pad_width), (0, 0)), mode='constant', constant_values=0)\n",
    "#         padded_targets = np.pad(targets, (0, pad_width), mode='constant', constant_values=0)\n",
    "#     else:\n",
    "#         padded_features = features[:max_riders, :]\n",
    "#         padded_targets = targets[:max_riders]\n",
    "#     races_test_padded.append(padded_features)\n",
    "#     targets_test_padded.append(padded_targets)\n",
    "\n",
    "# # Find maximum number of features\n",
    "# max_features = max(\n",
    "#     races_train[0].shape[1] if races_train else 0,\n",
    "#     races_test[0].shape[1] if races_test else 0\n",
    "# )\n",
    "\n",
    "# # Function to pad races, targets, and rider names\n",
    "# def pad_sequence(sequence, max_length, padding_value=0):\n",
    "#     sequence = list(sequence)\n",
    "#     padding_needed = max_length - len(sequence)\n",
    "#     if padding_needed > 0:\n",
    "#         sequence.extend([padding_value] * padding_needed)\n",
    "#     return sequence\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.array(races_train)\n",
    "y_train = np.array(targets_train)\n",
    "rider_names_train = np.array(rider_names_train, dtype=object)\n",
    "\n",
    "X_test = np.array(races_test)\n",
    "y_test = np.array(targets_test)\n",
    "rider_names_test = np.array(rider_names_test, dtype=object)\n",
    "\n",
    "# Save the data\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('rider_names_train.npy', rider_names_train)\n",
    "\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_test.npy', y_test)\n",
    "np.save('rider_names_test.npy', rider_names_test)\n",
    "\n",
    "print(\"Data preprocessing completed and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
