{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1160b5470>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pytorch\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2034, 207, 227)\n",
      "y_train shape: (2034, 207)\n",
      "X_test shape: (153, 207, 227)\n",
      "y_test shape: (153, 207)\n"
     ]
    }
   ],
   "source": [
    "# Load the data (adjust file paths as needed)\n",
    "X_train = np.load('X_train.npy', allow_pickle=True)\n",
    "y_train = np.load('y_train.npy', allow_pickle=True)\n",
    "X_test = np.load('X_test.npy', allow_pickle=True)\n",
    "y_test = np.load('y_test.npy', allow_pickle=True)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')  # Expected: (num_races_train, max_riders, num_features)\n",
    "print(f'y_train shape: {y_train.shape}')  # Expected: (num_races_train, max_riders)\n",
    "print(f'X_test shape: {X_test.shape}')    # Expected: (num_races_test, max_riders, num_features)\n",
    "print(f'y_test shape: {y_test.shape}')    # Expected: (num_races_test, max_riders)\n",
    "\n",
    "# Flatten the data for scikit-learn models\n",
    "X_train_flat = X_train.reshape(-1, X_train.shape[2])    # Shape: (num_races_train * max_riders, num_features)\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[2])       # Shape: (num_races_test * max_riders, num_features)\n",
    "\n",
    "# Flatten the targets\n",
    "y_train_flat = y_train.flatten()  # Shape: (num_races_train * max_riders,)\n",
    "y_test_flat = y_test.flatten()    # Shape: (num_races_test * max_riders,)\n",
    "\n",
    "# Filter out invalid targets (if necessary)\n",
    "valid_indices_train = y_train_flat > 0\n",
    "valid_indices_test = y_test_flat > 0\n",
    "\n",
    "X_train_flat = X_train_flat[valid_indices_train]\n",
    "y_train_flat = y_train_flat[valid_indices_train]\n",
    "\n",
    "X_test_flat = X_test_flat[valid_indices_test]\n",
    "y_test_flat = y_test_flat[valid_indices_test]\n",
    "\n",
    "# # Optionally scale the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_flat = scaler.fit_transform(X_train_flat)\n",
    "# X_test_flat = scaler.transform(X_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/775777151092792639', creation_time=1736268824287, experiment_id='775777151092792639', last_update_time=1736268824287, lifecycle_stage='active', name='Race_Prediction_Experiment_I', tags={'mlflow.note.content': 'Only first 3 riders have probability, so have in the '\n",
       "                        'test set'}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set MLflow experiment\n",
    "mlflow.set_tracking_uri(\"http://seito.lavbic.net:5000\")\n",
    "mlflow.set_experiment(\"Race_Prediction_Experiment_I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_class, param_grid, model_name, X_train, y_train, X_test, y_test):\n",
    "    from itertools import product\n",
    "    import pandas as pd\n",
    "\n",
    "    # Generate all combinations of hyperparameters\n",
    "    keys = param_grid.keys()\n",
    "    values = (param_grid[key] for key in keys)\n",
    "    param_combinations = [dict(zip(keys, combination)) for combination in product(*values)]\n",
    "\n",
    "    # For each combination, train and log the model\n",
    "    for idx, params in enumerate(param_combinations):\n",
    "        # Initialize model with current hyperparameters\n",
    "        model = model_class(**params)\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        smape = symmetric_mean_absolute_percentage_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Start MLflow run\n",
    "        with mlflow.start_run(run_name=f\"{model_name} - Run {idx+1}\"):\n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"model_class\", model_name)\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"test_mse\", mse)\n",
    "            mlflow.log_metric(\"test_mae\", mae)\n",
    "            mlflow.log_metric(\"test_r2\", r2)\n",
    "            mlflow.log_metric(\"test_mape\", mape)\n",
    "            mlflow.log_metric(\"test_rmse\", rmse)\n",
    "            mlflow.log_metric(\"test_smape\", smape)\n",
    "\n",
    "            # Log the model\n",
    "            input_example = X_train[:5]\n",
    "            signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                sk_model=model,\n",
    "                artifact_path=\"model\",\n",
    "                input_example=input_example,\n",
    "                signature=signature\n",
    "            )\n",
    "\n",
    "            # Print results\n",
    "            print(f\"\\n{model_name} Run {idx+1} parameters: {params}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test MSE: {mse:.4f}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test MAE: {mae:.4f}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test R^2 Score: {r2:.4f}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test MAPE: {mape:.4f}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test RMSE: {rmse:.4f}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test sMAPE: {smape:.4f}\")\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    epsilon = 1e-8  # Small number to prevent division by zero\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Avoid division by zero\n",
    "    mask = np.abs(y_true) > epsilon\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.inf  # Return infinity if no valid entries\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    return mape\n",
    "\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    diff = np.abs(y_pred - y_true)\n",
    "    # Avoid division by zero\n",
    "    mask = denominator != 0\n",
    "    smape = np.mean((diff[mask] / denominator[mask])) * 100\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Run 1 parameters: {}\n",
      "Linear Regression Run 1 Test MSE: 0.0000\n",
      "Linear Regression Run 1 Test MAE: 0.0000\n",
      "Linear Regression Run 1 Test R^2 Score: 1.0000\n",
      "Linear Regression Run 1 Test MAPE: 0.0000\n",
      "Linear Regression Run 1 Test RMSE: 0.0000\n",
      "Linear Regression Run 1 Test sMAPE: 0.0000\n",
      "üèÉ View run Linear Regression - Run 1 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/e81933db6cea4ffaa7d8ea0c6a04c699\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    }
   ],
   "source": [
    "linear_reg = LinearRegression\n",
    "param_grid_lr = {\n",
    "    # No hyperparameters to tune\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=linear_reg,\n",
    "    param_grid=param_grid_lr,\n",
    "    model_name=\"Linear Regression\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Regression Run 1 parameters: {'alpha': 0.1}\n",
      "Ridge Regression Run 1 Test MSE: 0.0000\n",
      "Ridge Regression Run 1 Test MAE: 0.0000\n",
      "Ridge Regression Run 1 Test R^2 Score: 1.0000\n",
      "Ridge Regression Run 1 Test MAPE: 0.0000\n",
      "Ridge Regression Run 1 Test RMSE: 0.0000\n",
      "Ridge Regression Run 1 Test sMAPE: 0.0000\n",
      "üèÉ View run Ridge Regression - Run 1 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/cc90f27ea5b54aa9879d00391bf8e608\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Ridge Regression Run 2 parameters: {'alpha': 0.9}\n",
      "Ridge Regression Run 2 Test MSE: 0.0000\n",
      "Ridge Regression Run 2 Test MAE: 0.0000\n",
      "Ridge Regression Run 2 Test R^2 Score: 1.0000\n",
      "Ridge Regression Run 2 Test MAPE: 0.0000\n",
      "Ridge Regression Run 2 Test RMSE: 0.0000\n",
      "Ridge Regression Run 2 Test sMAPE: 0.0000\n",
      "üèÉ View run Ridge Regression - Run 2 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/5ad942ac29744bc9aa3ce2b6b703ef98\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Ridge Regression Run 3 parameters: {'alpha': 1.0}\n",
      "Ridge Regression Run 3 Test MSE: 0.0000\n",
      "Ridge Regression Run 3 Test MAE: 0.0000\n",
      "Ridge Regression Run 3 Test R^2 Score: 1.0000\n",
      "Ridge Regression Run 3 Test MAPE: 0.0000\n",
      "Ridge Regression Run 3 Test RMSE: 0.0000\n",
      "Ridge Regression Run 3 Test sMAPE: 0.0000\n",
      "üèÉ View run Ridge Regression - Run 3 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/64537c325f6847a0ae88cc812c50f846\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Ridge Regression Run 4 parameters: {'alpha': 1.5}\n",
      "Ridge Regression Run 4 Test MSE: 0.0000\n",
      "Ridge Regression Run 4 Test MAE: 0.0000\n",
      "Ridge Regression Run 4 Test R^2 Score: 1.0000\n",
      "Ridge Regression Run 4 Test MAPE: 0.0000\n",
      "Ridge Regression Run 4 Test RMSE: 0.0000\n",
      "Ridge Regression Run 4 Test sMAPE: 0.0000\n",
      "üèÉ View run Ridge Regression - Run 4 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/08d11fe19bf04adf98a9e2c2cc3fc62b\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Ridge Regression Run 5 parameters: {'alpha': 2.0}\n",
      "Ridge Regression Run 5 Test MSE: 0.0000\n",
      "Ridge Regression Run 5 Test MAE: 0.0000\n",
      "Ridge Regression Run 5 Test R^2 Score: 1.0000\n",
      "Ridge Regression Run 5 Test MAPE: 0.0000\n",
      "Ridge Regression Run 5 Test RMSE: 0.0000\n",
      "Ridge Regression Run 5 Test sMAPE: 0.0000\n",
      "üèÉ View run Ridge Regression - Run 5 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/e54fd48d19134519b3e7e0d562e26fd4\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Ridge Regression Run 6 parameters: {'alpha': 10.0}\n",
      "Ridge Regression Run 6 Test MSE: 0.0000\n",
      "Ridge Regression Run 6 Test MAE: 0.0000\n",
      "Ridge Regression Run 6 Test R^2 Score: 1.0000\n",
      "Ridge Regression Run 6 Test MAPE: 0.0000\n",
      "Ridge Regression Run 6 Test RMSE: 0.0000\n",
      "Ridge Regression Run 6 Test sMAPE: 0.0000\n",
      "üèÉ View run Ridge Regression - Run 6 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/5dfe1b08c99640a1b6644b2ca819059f\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    }
   ],
   "source": [
    "ridge_reg = Ridge\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 0.9, 1.0, 1.5, 2.0, 10.0]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=ridge_reg,\n",
    "    param_grid=param_grid_ridge,\n",
    "    model_name=\"Ridge Regression\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Run 1 parameters: {'alpha': 0.0001, 'max_iter': 10000}\n",
      "Lasso Regression Run 1 Test MSE: 0.0000\n",
      "Lasso Regression Run 1 Test MAE: 0.0000\n",
      "Lasso Regression Run 1 Test R^2 Score: 1.0000\n",
      "Lasso Regression Run 1 Test MAPE: 0.0000\n",
      "Lasso Regression Run 1 Test RMSE: 0.0000\n",
      "Lasso Regression Run 1 Test sMAPE: 0.0000\n",
      "üèÉ View run Lasso Regression - Run 1 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/1121a8fe6aa2495f9b9a2baabc7ade5c\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Run 2 parameters: {'alpha': 0.001, 'max_iter': 10000}\n",
      "Lasso Regression Run 2 Test MSE: 0.0000\n",
      "Lasso Regression Run 2 Test MAE: 0.0000\n",
      "Lasso Regression Run 2 Test R^2 Score: 1.0000\n",
      "Lasso Regression Run 2 Test MAPE: 0.0000\n",
      "Lasso Regression Run 2 Test RMSE: 0.0000\n",
      "Lasso Regression Run 2 Test sMAPE: 0.0000\n",
      "üèÉ View run Lasso Regression - Run 2 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/3094534ced234af08f341e7b48e9c974\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Run 3 parameters: {'alpha': 0.01, 'max_iter': 10000}\n",
      "Lasso Regression Run 3 Test MSE: 0.0000\n",
      "Lasso Regression Run 3 Test MAE: 0.0000\n",
      "Lasso Regression Run 3 Test R^2 Score: 1.0000\n",
      "Lasso Regression Run 3 Test MAPE: 0.0000\n",
      "Lasso Regression Run 3 Test RMSE: 0.0000\n",
      "Lasso Regression Run 3 Test sMAPE: 0.0000\n",
      "üèÉ View run Lasso Regression - Run 3 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/39ce72a7117747538600ae565f04b536\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Run 4 parameters: {'alpha': 0.1, 'max_iter': 10000}\n",
      "Lasso Regression Run 4 Test MSE: 0.0000\n",
      "Lasso Regression Run 4 Test MAE: 0.0000\n",
      "Lasso Regression Run 4 Test R^2 Score: 1.0000\n",
      "Lasso Regression Run 4 Test MAPE: 0.0000\n",
      "Lasso Regression Run 4 Test RMSE: 0.0000\n",
      "Lasso Regression Run 4 Test sMAPE: 0.0000\n",
      "üèÉ View run Lasso Regression - Run 4 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/35989fcbb88e4ad08ee48f64efaf68df\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Run 5 parameters: {'alpha': 1.0, 'max_iter': 10000}\n",
      "Lasso Regression Run 5 Test MSE: 0.0000\n",
      "Lasso Regression Run 5 Test MAE: 0.0000\n",
      "Lasso Regression Run 5 Test R^2 Score: 1.0000\n",
      "Lasso Regression Run 5 Test MAPE: 0.0000\n",
      "Lasso Regression Run 5 Test RMSE: 0.0000\n",
      "Lasso Regression Run 5 Test sMAPE: 0.0000\n",
      "üèÉ View run Lasso Regression - Run 5 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/09bf18ca520f4896830537057c362d95\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Run 6 parameters: {'alpha': 1.5, 'max_iter': 10000}\n",
      "Lasso Regression Run 6 Test MSE: 0.0000\n",
      "Lasso Regression Run 6 Test MAE: 0.0000\n",
      "Lasso Regression Run 6 Test R^2 Score: 1.0000\n",
      "Lasso Regression Run 6 Test MAPE: 0.0000\n",
      "Lasso Regression Run 6 Test RMSE: 0.0000\n",
      "Lasso Regression Run 6 Test sMAPE: 0.0000\n",
      "üèÉ View run Lasso Regression - Run 6 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/d24528fdf4c348a7b8456772aba112b9\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Run 7 parameters: {'alpha': 2.0, 'max_iter': 10000}\n",
      "Lasso Regression Run 7 Test MSE: 0.0000\n",
      "Lasso Regression Run 7 Test MAE: 0.0000\n",
      "Lasso Regression Run 7 Test R^2 Score: 1.0000\n",
      "Lasso Regression Run 7 Test MAPE: 0.0000\n",
      "Lasso Regression Run 7 Test RMSE: 0.0000\n",
      "Lasso Regression Run 7 Test sMAPE: 0.0000\n",
      "üèÉ View run Lasso Regression - Run 7 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/a61696312fb44fd09b068143a3266b97\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Run 8 parameters: {'alpha': 10.0, 'max_iter': 10000}\n",
      "Lasso Regression Run 8 Test MSE: 0.0000\n",
      "Lasso Regression Run 8 Test MAE: 0.0000\n",
      "Lasso Regression Run 8 Test R^2 Score: 1.0000\n",
      "Lasso Regression Run 8 Test MAPE: 0.0000\n",
      "Lasso Regression Run 8 Test RMSE: 0.0000\n",
      "Lasso Regression Run 8 Test sMAPE: 0.0000\n",
      "üèÉ View run Lasso Regression - Run 8 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/f844756c5f394eee8e13c5651718f92c\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    }
   ],
   "source": [
    "lasso_reg = Lasso\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 1.5, 2.0, 10.0],\n",
    "    'max_iter': [10000]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=lasso_reg,\n",
    "    param_grid=param_grid_lasso,\n",
    "    model_name=\"Lasso Regression\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Regressor Run 1 parameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "Decision Tree Regressor Run 1 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 1 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 1 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 1 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 1 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 1 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 1 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/c52625310b2e4a409b8c75a58a558d7a\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 2 parameters: {'max_depth': None, 'min_samples_split': 5}\n",
      "Decision Tree Regressor Run 2 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 2 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 2 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 2 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 2 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 2 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 2 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/216933ddaa5547d887e10faee68ea8d8\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 3 parameters: {'max_depth': None, 'min_samples_split': 10}\n",
      "Decision Tree Regressor Run 3 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 3 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 3 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 3 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 3 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 3 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 3 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/289e045930ca4b118b48093bec65cf8e\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 4 parameters: {'max_depth': 5, 'min_samples_split': 2}\n",
      "Decision Tree Regressor Run 4 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 4 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 4 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 4 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 4 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 4 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 4 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/a330e9a35034400c91e8f71a6ff4b9f6\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 5 parameters: {'max_depth': 5, 'min_samples_split': 5}\n",
      "Decision Tree Regressor Run 5 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 5 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 5 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 5 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 5 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 5 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 5 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/6fbc7076b83a43298de178624db23793\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 6 parameters: {'max_depth': 5, 'min_samples_split': 10}\n",
      "Decision Tree Regressor Run 6 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 6 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 6 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 6 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 6 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 6 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 6 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/d4faae92ce974f86a93b91d9c7b8a607\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 7 parameters: {'max_depth': 10, 'min_samples_split': 2}\n",
      "Decision Tree Regressor Run 7 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 7 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 7 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 7 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 7 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 7 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 7 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/4ddbc79288454533ae4ab00f4f5b310e\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 8 parameters: {'max_depth': 10, 'min_samples_split': 5}\n",
      "Decision Tree Regressor Run 8 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 8 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 8 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 8 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 8 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 8 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 8 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/d9c31fdaac0c4d819a6c5f79c9fea0c6\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 9 parameters: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Decision Tree Regressor Run 9 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 9 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 9 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 9 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 9 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 9 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 9 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/81a61152460140a4bf47bd531e141931\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 10 parameters: {'max_depth': 20, 'min_samples_split': 2}\n",
      "Decision Tree Regressor Run 10 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 10 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 10 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 10 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 10 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 10 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 10 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/681427d8a202482c81ad5ccbba322261\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 11 parameters: {'max_depth': 20, 'min_samples_split': 5}\n",
      "Decision Tree Regressor Run 11 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 11 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 11 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 11 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 11 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 11 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 11 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/81c1fd681a344d4481a805f0e79ac375\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "Decision Tree Regressor Run 12 parameters: {'max_depth': 20, 'min_samples_split': 10}\n",
      "Decision Tree Regressor Run 12 Test MSE: 0.0000\n",
      "Decision Tree Regressor Run 12 Test MAE: 0.0000\n",
      "Decision Tree Regressor Run 12 Test R^2 Score: 1.0000\n",
      "Decision Tree Regressor Run 12 Test MAPE: 0.0000\n",
      "Decision Tree Regressor Run 12 Test RMSE: 0.0000\n",
      "Decision Tree Regressor Run 12 Test sMAPE: 0.0000\n",
      "üèÉ View run Decision Tree Regressor - Run 12 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/105b2d09d5d948bf80f6106bc9a41c9a\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    }
   ],
   "source": [
    "decision_tree_reg = DecisionTreeRegressor\n",
    "param_grid_dtree_reg = {\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=decision_tree_reg,\n",
    "    param_grid=param_grid_dtree_reg,\n",
    "    model_name=\"Decision Tree Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model_class = SVR\n",
    "param_grid_svr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'epsilon': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=svr_model_class,\n",
    "    param_grid=param_grid_svr,\n",
    "    model_name=\"Support Vector Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reg = RandomForestRegressor()\n",
    "param_grid_rf_reg = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model=random_forest_reg,\n",
    "    param_grid=param_grid_rf_reg,\n",
    "    model_name=\"Random Forest Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "gb_regressor = GradientBoostingRegressor()\n",
    "param_grid_gb_reg = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model=gb_regressor,\n",
    "    param_grid=param_grid_gb_reg,\n",
    "    model_name=\"Gradient Boosting Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Regressor Run 1 parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 3, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 1 Test MSE: 0.0000\n",
      "XGBoost Regressor Run 1 Test MAE: 0.0000\n",
      "XGBoost Regressor Run 1 Test R^2 Score: 1.0000\n",
      "XGBoost Regressor Run 1 Test MAPE: 0.0000\n",
      "XGBoost Regressor Run 1 Test RMSE: 0.0000\n",
      "XGBoost Regressor Run 1 Test sMAPE: 0.0000\n",
      "üèÉ View run XGBoost Regressor - Run 1 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/bbd0c70049b34962bcd180e5cfad896e\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "XGBoost Regressor Run 2 parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 5, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 2 Test MSE: 0.0000\n",
      "XGBoost Regressor Run 2 Test MAE: 0.0000\n",
      "XGBoost Regressor Run 2 Test R^2 Score: 1.0000\n",
      "XGBoost Regressor Run 2 Test MAPE: 0.0000\n",
      "XGBoost Regressor Run 2 Test RMSE: 0.0000\n",
      "XGBoost Regressor Run 2 Test sMAPE: 0.0000\n",
      "üèÉ View run XGBoost Regressor - Run 2 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/d81ebf11be174054bddb659dcc63f807\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "XGBoost Regressor Run 3 parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 3 Test MSE: 0.0000\n",
      "XGBoost Regressor Run 3 Test MAE: 0.0000\n",
      "XGBoost Regressor Run 3 Test R^2 Score: 1.0000\n",
      "XGBoost Regressor Run 3 Test MAPE: 0.0000\n",
      "XGBoost Regressor Run 3 Test RMSE: 0.0000\n",
      "XGBoost Regressor Run 3 Test sMAPE: 0.0000\n",
      "üèÉ View run XGBoost Regressor - Run 3 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/249720f7d73641739472ccfc2f949288\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "XGBoost Regressor Run 4 parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 5, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 4 Test MSE: 0.0000\n",
      "XGBoost Regressor Run 4 Test MAE: 0.0000\n",
      "XGBoost Regressor Run 4 Test R^2 Score: 1.0000\n",
      "XGBoost Regressor Run 4 Test MAPE: 0.0000\n",
      "XGBoost Regressor Run 4 Test RMSE: 0.0000\n",
      "XGBoost Regressor Run 4 Test sMAPE: 0.0000\n",
      "üèÉ View run XGBoost Regressor - Run 4 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/b4211148065349cbb0e421b0a9e60623\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "XGBoost Regressor Run 5 parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 3, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 5 Test MSE: 0.0000\n",
      "XGBoost Regressor Run 5 Test MAE: 0.0000\n",
      "XGBoost Regressor Run 5 Test R^2 Score: 1.0000\n",
      "XGBoost Regressor Run 5 Test MAPE: 0.0000\n",
      "XGBoost Regressor Run 5 Test RMSE: 0.0000\n",
      "XGBoost Regressor Run 5 Test sMAPE: 0.0000\n",
      "üèÉ View run XGBoost Regressor - Run 5 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/95faae71ba964f03bd011eed6106cad5\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "XGBoost Regressor Run 6 parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 5, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 6 Test MSE: 0.0000\n",
      "XGBoost Regressor Run 6 Test MAE: 0.0000\n",
      "XGBoost Regressor Run 6 Test R^2 Score: 1.0000\n",
      "XGBoost Regressor Run 6 Test MAPE: 0.0000\n",
      "XGBoost Regressor Run 6 Test RMSE: 0.0000\n",
      "XGBoost Regressor Run 6 Test sMAPE: 0.0000\n",
      "üèÉ View run XGBoost Regressor - Run 6 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/82baec7156a842e9842670423c462bc9\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "XGBoost Regressor Run 7 parameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 7 Test MSE: 0.0000\n",
      "XGBoost Regressor Run 7 Test MAE: 0.0000\n",
      "XGBoost Regressor Run 7 Test R^2 Score: 1.0000\n",
      "XGBoost Regressor Run 7 Test MAPE: 0.0000\n",
      "XGBoost Regressor Run 7 Test RMSE: 0.0000\n",
      "XGBoost Regressor Run 7 Test sMAPE: 0.0000\n",
      "üèÉ View run XGBoost Regressor - Run 7 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/be4831b54dde473fbb98303309d6fb87\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "XGBoost Regressor Run 8 parameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 5, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 8 Test MSE: 0.0000\n",
      "XGBoost Regressor Run 8 Test MAE: 0.0000\n",
      "XGBoost Regressor Run 8 Test R^2 Score: 1.0000\n",
      "XGBoost Regressor Run 8 Test MAPE: 0.0000\n",
      "XGBoost Regressor Run 8 Test RMSE: 0.0000\n",
      "XGBoost Regressor Run 8 Test sMAPE: 0.0000\n",
      "üèÉ View run XGBoost Regressor - Run 8 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/d82997fd0dba4a24849cb2e681db0065\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    }
   ],
   "source": [
    "xgboost_reg = xgb.XGBRegressor\n",
    "param_grid_xgb_reg = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=xgboost_reg,\n",
    "    param_grid=param_grid_xgb_reg,\n",
    "    model_name=\"XGBoost Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_and_evaluate_model() got an unexpected keyword argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m lgbm_reg \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor()\n\u001b[1;32m      2\u001b[0m param_grid_lgbm_reg \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m63\u001b[39m]\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlgbm_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_grid_lgbm_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLightGBM Regressor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test_flat\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_and_evaluate_model() got an unexpected keyword argument 'model'"
     ]
    }
   ],
   "source": [
    "lgbm_reg = lgb.LGBMRegressor()\n",
    "param_grid_lgbm_reg = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'num_leaves': [31, 63]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model=lgbm_reg,\n",
    "    param_grid=param_grid_lgbm_reg,\n",
    "    model_name=\"LightGBM Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Nearest Neighbors Regressor Run 1 parameters: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "K-Nearest Neighbors Regressor Run 1 Test MSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 1 Test MAE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 1 Test R^2 Score: 1.0000\n",
      "K-Nearest Neighbors Regressor Run 1 Test MAPE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 1 Test RMSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 1 Test sMAPE: 0.0000\n",
      "üèÉ View run K-Nearest Neighbors Regressor - Run 1 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/3a66a4020b6c44adb55a3c6dc9d4101a\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "K-Nearest Neighbors Regressor Run 2 parameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "K-Nearest Neighbors Regressor Run 2 Test MSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 2 Test MAE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 2 Test R^2 Score: 1.0000\n",
      "K-Nearest Neighbors Regressor Run 2 Test MAPE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 2 Test RMSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 2 Test sMAPE: 0.0000\n",
      "üèÉ View run K-Nearest Neighbors Regressor - Run 2 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/44c5f87e5d6d4480852a40662798ad19\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "K-Nearest Neighbors Regressor Run 3 parameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "K-Nearest Neighbors Regressor Run 3 Test MSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 3 Test MAE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 3 Test R^2 Score: 1.0000\n",
      "K-Nearest Neighbors Regressor Run 3 Test MAPE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 3 Test RMSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 3 Test sMAPE: 0.0000\n",
      "üèÉ View run K-Nearest Neighbors Regressor - Run 3 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/f2caa83bde824c548643f631dc80829e\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "K-Nearest Neighbors Regressor Run 4 parameters: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "K-Nearest Neighbors Regressor Run 4 Test MSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 4 Test MAE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 4 Test R^2 Score: 1.0000\n",
      "K-Nearest Neighbors Regressor Run 4 Test MAPE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 4 Test RMSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 4 Test sMAPE: 0.0000\n",
      "üèÉ View run K-Nearest Neighbors Regressor - Run 4 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/e3542dcae80b4707ae3b23ded2f575f8\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "K-Nearest Neighbors Regressor Run 5 parameters: {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "K-Nearest Neighbors Regressor Run 5 Test MSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 5 Test MAE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 5 Test R^2 Score: 1.0000\n",
      "K-Nearest Neighbors Regressor Run 5 Test MAPE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 5 Test RMSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 5 Test sMAPE: 0.0000\n",
      "üèÉ View run K-Nearest Neighbors Regressor - Run 5 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/3aedb2ac95e84da88a01e35a2b3e910a\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "\n",
      "K-Nearest Neighbors Regressor Run 6 parameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "K-Nearest Neighbors Regressor Run 6 Test MSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 6 Test MAE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 6 Test R^2 Score: 1.0000\n",
      "K-Nearest Neighbors Regressor Run 6 Test MAPE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 6 Test RMSE: 0.0000\n",
      "K-Nearest Neighbors Regressor Run 6 Test sMAPE: 0.0000\n",
      "üèÉ View run K-Nearest Neighbors Regressor - Run 6 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/10b567319aaf4086b04e0362d27988b5\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_model = KNeighborsRegressor\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=knn_model,\n",
    "    param_grid=param_grid_knn,\n",
    "    model_name=\"K-Nearest Neighbors Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128):\n",
    "        super(RaceRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)  # Output a score for each rider\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x should have shape (batch_size, num_features)\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RaceRegressionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)  # Shape: (num_samples, num_features)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)  # Shape: (num_samples,)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        return X, y\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = RaceRegressionDataset(X_train_flat, y_train_flat)\n",
    "test_dataset = RaceRegressionDataset(X_test_flat, y_test_flat)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:18:16,484] A new study created in memory with name: no-name-40f59f35-04dc-41bf-9039-afdf372b801a\n",
      "[I 2025-01-09 10:18:21,774] Trial 0 finished with value: 0.0966482013463974 and parameters: {'hidden_size': 128, 'learning_rate': 0.002157631739829833, 'weight_decay': 0.00024634599017599103, 'num_epochs': 17, 'batch_size': 64}. Best is trial 0 with value: 0.0966482013463974.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 0 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/ffc94545a25d4c73830d478981ff7d14\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:18:25,749] Trial 1 finished with value: 0.20904843509197235 and parameters: {'hidden_size': 64, 'learning_rate': 0.007551577199034414, 'weight_decay': 0.00015008894709472555, 'num_epochs': 10, 'batch_size': 128}. Best is trial 0 with value: 0.0966482013463974.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 1 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/389673f5c39b43bfb8fa960c579599ea\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:18:31,305] Trial 2 finished with value: 0.07524678856134415 and parameters: {'hidden_size': 256, 'learning_rate': 0.0028225810408850417, 'weight_decay': 0.0007046069577602527, 'num_epochs': 26, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 2 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/129959e61a59446384d309ec0ce64b83\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:18:35,912] Trial 3 finished with value: 0.24459625780582428 and parameters: {'hidden_size': 256, 'learning_rate': 0.006513732904498579, 'weight_decay': 0.0004036646160107114, 'num_epochs': 14, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 3 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/b6edb679952f4bffa07137e1e14682fb\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:18:40,331] Trial 4 finished with value: 0.19303226470947266 and parameters: {'hidden_size': 64, 'learning_rate': 0.0001360822393902129, 'weight_decay': 0.0007161250755017757, 'num_epochs': 21, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 4 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/c08fca7bf4db4df2835295611b98d415\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "üèÉ View run Neural Network MAE Run 5 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/bec9a49eaa8448d1b66d3ce9bdaf7bbd\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:18:45,573] Trial 5 finished with value: 0.20796599984169006 and parameters: {'hidden_size': 128, 'learning_rate': 0.004091217486473826, 'weight_decay': 0.0004201280728359196, 'num_epochs': 28, 'batch_size': 256}. Best is trial 2 with value: 0.07524678856134415.\n",
      "[I 2025-01-09 10:18:50,805] Trial 6 finished with value: 0.0777682512998581 and parameters: {'hidden_size': 256, 'learning_rate': 0.0034257330949070517, 'weight_decay': 0.0005166612169329545, 'num_epochs': 19, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 6 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/428b5264381f4d3890aa63a2c9777732\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:18:55,439] Trial 7 finished with value: 0.2074243575334549 and parameters: {'hidden_size': 128, 'learning_rate': 0.008295015881908058, 'weight_decay': 0.0005792075771926575, 'num_epochs': 19, 'batch_size': 128}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 7 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/e27da3a69624448c9f5398820d064bc2\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:18:59,805] Trial 8 finished with value: 0.2250986397266388 and parameters: {'hidden_size': 64, 'learning_rate': 0.009930459500792407, 'weight_decay': 0.0006556194790052821, 'num_epochs': 11, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 8 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/711fe49bb25c42edbfced7db35525b7c\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:04,254] Trial 9 finished with value: 0.40690141916275024 and parameters: {'hidden_size': 256, 'learning_rate': 0.007851997747925, 'weight_decay': 0.00012327231127598126, 'num_epochs': 11, 'batch_size': 256}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 9 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/bf91e9d6a8344a0a84abfd85eb3b8403\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:09,387] Trial 10 finished with value: 0.13775208592414856 and parameters: {'hidden_size': 256, 'learning_rate': 0.0007370315283262859, 'weight_decay': 0.0009972834799366853, 'num_epochs': 30, 'batch_size': 128}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 10 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/1d749059c98b48eeb804bc521ba9b059\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:14,769] Trial 11 finished with value: 0.10511182993650436 and parameters: {'hidden_size': 256, 'learning_rate': 0.003918906112156891, 'weight_decay': 0.0008412334294209073, 'num_epochs': 24, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 11 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/86ee14bcd2ef47ac8472f08dda313175\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:19,837] Trial 12 finished with value: 0.10956001281738281 and parameters: {'hidden_size': 256, 'learning_rate': 0.0024515443302800975, 'weight_decay': 0.0005109050137390424, 'num_epochs': 23, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 12 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/b6a11fdedc87406d80af8d81e63575b2\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:25,003] Trial 13 finished with value: 0.12516681849956512 and parameters: {'hidden_size': 256, 'learning_rate': 0.0052809300924140734, 'weight_decay': 0.0007892759724480732, 'num_epochs': 27, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 13 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/94d3f68eff1c4cdd920b0e5f416ab390\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:29,726] Trial 14 finished with value: 0.1450427770614624 and parameters: {'hidden_size': 256, 'learning_rate': 0.0026708442383857655, 'weight_decay': 0.00033199314468094387, 'num_epochs': 17, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 14 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/c47ae74bb2bb4f97b3e892303688456c\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:35,716] Trial 15 finished with value: 0.2979873716831207 and parameters: {'hidden_size': 256, 'learning_rate': 0.004995442198011131, 'weight_decay': 0.000988403653825521, 'num_epochs': 25, 'batch_size': 256}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 15 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/c0255f5cb7db4e458b0b8526ee6b0410\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:40,809] Trial 16 finished with value: 0.11716160178184509 and parameters: {'hidden_size': 256, 'learning_rate': 0.0014487102491458279, 'weight_decay': 0.0005887178849470995, 'num_epochs': 21, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 16 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/eda2831502da47a3967f0d3dd5543c2c\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:45,659] Trial 17 finished with value: 0.1615927368402481 and parameters: {'hidden_size': 256, 'learning_rate': 0.0034638849391990766, 'weight_decay': 0.0008683105277465863, 'num_epochs': 15, 'batch_size': 64}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 17 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/b426871596f1416f9107fa2ed9a93c84\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:50,317] Trial 18 finished with value: 0.12053829431533813 and parameters: {'hidden_size': 64, 'learning_rate': 0.005605759042661504, 'weight_decay': 0.0007027356360157736, 'num_epochs': 26, 'batch_size': 128}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 18 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/46b3d5292ddf4a1a9255061ecd76ea10\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-09 10:19:55,387] Trial 19 finished with value: 0.18014822900295258 and parameters: {'hidden_size': 128, 'learning_rate': 0.0032282057699583437, 'weight_decay': 1.8283620788416455e-05, 'num_epochs': 30, 'batch_size': 256}. Best is trial 2 with value: 0.07524678856134415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 19 at: http://seito.lavbic.net:5000/#/experiments/414728986215934723/runs/176b1ba5e1244c028124f10493ae91fa\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/414728986215934723\n",
      "Best hyperparameters: {'hidden_size': 256, 'learning_rate': 0.0028225810408850417, 'weight_decay': 0.0007046069577602527, 'num_epochs': 26, 'batch_size': 64}\n",
      "Best sMAPE: 0.07524678856134415\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameter suggestions\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [64, 128, 256])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 10, 30)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [64, 128, 256])\n",
    "\n",
    "    # Create data loaders with the suggested batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    input_size = X_train_flat.shape[1]\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = RaceRegressionModel(input_size, hidden_size).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=f\"Neural Network MAE Run {trial.number}\"):\n",
    "        mlflow.log_params({\n",
    "            'model_class': 'RaceRegressionModel',\n",
    "            'hidden_size': hidden_size,\n",
    "            'learning_rate': learning_rate,\n",
    "            'weight_decay': weight_decay,\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size\n",
    "        })\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "            average_loss = total_loss / len(train_loader.dataset)\n",
    "            mlflow.log_metric(\"train_loss\", average_loss, step=epoch)\n",
    "\n",
    "        # Evaluation on test set\n",
    "        model.eval()\n",
    "        y_true_list = []\n",
    "        y_pred_list = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                outputs = model(X_batch)\n",
    "                y_true_list.extend(y_batch.cpu().numpy())\n",
    "                y_pred_list.extend(outputs.cpu().numpy())\n",
    "\n",
    "        y_true_array = np.array(y_true_list)\n",
    "        y_pred_array = np.array(y_pred_list)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        mse = mean_squared_error(y_true_array, y_pred_array)\n",
    "        mae = mean_absolute_error(y_true_array, y_pred_array)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_true_array, y_pred_array)\n",
    "        mape = mean_absolute_percentage_error(y_true_array, y_pred_array)\n",
    "        smape = symmetric_mean_absolute_percentage_error(y_true_array, y_pred_array)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            'test_mse': mse,\n",
    "            'test_mae': mae,\n",
    "            'test_rmse': rmse,\n",
    "            'test_r2': r2,\n",
    "            'test_mape': mape,\n",
    "            'test_smape': smape\n",
    "        })\n",
    "\n",
    "        # Log the model\n",
    "        input_example = X_train_flat[:5].astype(np.float32)\n",
    "        input_example_tensor = torch.tensor(input_example, dtype=torch.float32).to(device)\n",
    "        signature = infer_signature(\n",
    "            input_example,\n",
    "            model(input_example_tensor).cpu().detach().numpy()\n",
    "        )\n",
    "        mlflow.pytorch.log_model(\n",
    "            pytorch_model=model,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=input_example,\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    # Return the metric to optimize\n",
    "    return mae\n",
    "\n",
    "# Create an Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best MAE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving best performing model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Parameters:\n",
      "{'batch_size': '256', 'num_epochs': '20', 'model_class': 'RaceRegressionModel', 'hidden_size': '64', 'learning_rate': '0.007408841693587583', 'weight_decay': '0.0007490024204516086'}\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# set the tracking uri\n",
    "mlflow.set_tracking_uri(\"http://seito.lavbic.net:5000\")\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# get the best model id\n",
    "experiment_name = \"Race_Prediction_Experiment_I\"\n",
    "experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "runs = client.search_runs(experiment_id, order_by=[\"metrics.test_mae ASC\"], max_results=1)\n",
    "best_run = runs[0]\n",
    "\n",
    "best_params = best_run.data.params\n",
    "print(\"Best Run Parameters:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 106.6261\n",
      "Epoch 2/20, Loss: 3.3555\n",
      "Epoch 3/20, Loss: 0.1431\n",
      "Epoch 4/20, Loss: 0.0721\n",
      "Epoch 5/20, Loss: 0.0687\n",
      "Epoch 6/20, Loss: 0.0677\n",
      "Epoch 7/20, Loss: 0.0669\n",
      "Epoch 8/20, Loss: 0.0660\n",
      "Epoch 9/20, Loss: 0.0655\n",
      "Epoch 10/20, Loss: 0.0652\n",
      "Epoch 11/20, Loss: 0.0655\n",
      "Epoch 12/20, Loss: 0.2737\n",
      "Epoch 13/20, Loss: 0.1603\n",
      "Epoch 14/20, Loss: 0.0675\n",
      "Epoch 15/20, Loss: 0.0642\n",
      "Epoch 16/20, Loss: 0.0622\n",
      "Epoch 17/20, Loss: 0.0619\n",
      "Epoch 18/20, Loss: 0.0626\n",
      "Epoch 19/20, Loss: 0.0629\n",
      "Epoch 20/20, Loss: 0.0624\n",
      "üèÉ View run Retrained Best Model at: http://seito.lavbic.net:5000/#/experiments/775777151092792639/runs/faddefe3cb5748b58e38563ea616268a\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/775777151092792639\n",
      "Training complete. Model and metrics logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Define the model class\n",
    "class RaceRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128):\n",
    "        super(RaceRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out.squeeze()\n",
    "\n",
    "# Define the dataset class\n",
    "class RaceRegressionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = RaceRegressionDataset(X_train_flat, y_train_flat)\n",
    "test_dataset = RaceRegressionDataset(X_test_flat, y_test_flat)\n",
    "\n",
    "# Create data loaders with the best batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=int(best_params['batch_size']), shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(best_params['batch_size']), shuffle=False, num_workers=0)\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "input_size = X_train_flat.shape[1]\n",
    "\n",
    "model = RaceRegressionModel(input_size, int(best_params['hidden_size'])).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=float(best_params['learning_rate']), weight_decay=float(best_params['weight_decay']))\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"Retrained Best Model\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = best_params['num_epochs']\n",
    "    for epoch in range(int(num_epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        average_loss = total_loss / len(train_loader.dataset)\n",
    "        mlflow.log_metric(\"train_loss\", average_loss, step=epoch)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}\")\n",
    "\n",
    "    # Evaluation on test set\n",
    "    model.eval()\n",
    "    y_true_list = []\n",
    "    y_pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            y_true_list.extend(y_batch.cpu().numpy())\n",
    "            y_pred_list.extend(outputs.cpu().numpy())\n",
    "\n",
    "    y_true_array = np.array(y_true_list)\n",
    "    y_pred_array = np.array(y_pred_list)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    mse = mean_squared_error(y_true_array, y_pred_array)\n",
    "    mae = mean_absolute_error(y_true_array, y_pred_array)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true_array, y_pred_array)\n",
    "\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "        epsilon = 1e-8  # Avoid division by zero\n",
    "        mask = np.abs(y_true) > epsilon\n",
    "        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "    def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "        denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "        diff = np.abs(y_pred - y_true)\n",
    "        mask = denominator != 0\n",
    "        return np.mean((diff[mask] / denominator[mask])) * 100\n",
    "\n",
    "    mape = mean_absolute_percentage_error(y_true_array, y_pred_array)\n",
    "    smape = symmetric_mean_absolute_percentage_error(y_true_array, y_pred_array)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        'test_mse': mse,\n",
    "        'test_mae': mae,\n",
    "        'test_rmse': rmse,\n",
    "        'test_r2': r2,\n",
    "        'test_mape': mape,\n",
    "        'test_smape': smape\n",
    "    })\n",
    "\n",
    "    # Log the model\n",
    "    input_example = X_train_flat[:5].astype(np.float32)\n",
    "    input_example_tensor = torch.tensor(input_example, dtype=torch.float32).to(device)\n",
    "    signature = infer_signature(\n",
    "        input_example,\n",
    "        model(input_example_tensor).cpu().detach().numpy()\n",
    "    )\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "print(\"Training complete. Model and metrics logged to MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promote model to production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.24.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"PyTorch version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (207, 227)\n",
      "Prediction: [0.27269816398620605, 0.2527596950531006, 0.26030707359313965, 0.20777678489685059, 0.19027400016784668, 0.2926747798919678, 0.40406009554862976, 0.2845776081085205, 0.22556281089782715, 0.20351195335388184, 0.2538764476776123, 0.27646660804748535, 0.22603297233581543, 0.19678139686584473, 0.14006435871124268, 0.1255316138267517, 0.29378199577331543, 0.20826363563537598, 0.17711138725280762, 0.276688814163208, 0.3010740280151367, 0.2258756160736084, 0.21817564964294434, 0.17943501472473145, 0.22046589851379395, 0.035171061754226685, 0.13812056183815002, 0.249375581741333, 0.29229092597961426, 0.322174072265625, 0.04750180244445801, 0.17222821712493896, 0.20850610733032227, 0.21213603019714355, 0.27309250831604004, 0.1721576452255249, 0.19855666160583496, 0.26486897468566895, 0.3014333248138428, 0.1888504922389984, 0.1979362964630127, 0.1669788360595703, 0.29357361793518066, 0.20566010475158691, 0.2508995532989502, 0.27065229415893555, 0.2933619022369385, 0.18437731266021729, 0.2733733654022217, 0.2462451457977295, 0.2746422290802002, 0.5013190507888794, 0.2318403720855713, 0.3003828525543213, -0.024896712973713875, 0.4345358908176422, -0.04780356585979462, 0.27588820457458496, 0.22240376472473145, 0.15108132362365723, -0.07849321514368057, 0.39487576484680176, 0.21044643223285675, 0.02619585208594799, 0.464415580034256, 0.20067667961120605, 0.14841341972351074, 0.6224539279937744, 0.08528834581375122, 0.21483492851257324, 0.19321513175964355, 0.2318110466003418, 0.16654086112976074, 0.19457650184631348, 0.19618424773216248, 0.23554396629333496, -0.08506938070058823, 0.1976320743560791, 0.28976988792419434, 0.23024439811706543, 0.29093146324157715, 0.2253739833831787, 0.1939997673034668, 0.30193209648132324, 0.3174550533294678, 0.21819567680358887, 0.17262065410614014, -0.023817943409085274, 0.24790000915527344, 0.14263218641281128, 0.17402052879333496, 0.15076768398284912, 0.2662198543548584, 0.3323543071746826, 0.23250365257263184, 0.32278919219970703, 0.03820398449897766, 0.19551777839660645, 0.2551133632659912, 0.254932165145874, -0.0253069419413805, 0.5442665219306946, 0.26316237449645996, 0.22753643989562988, 0.4152478575706482, 0.24159693717956543, -0.0842503011226654, 0.2388145923614502, 0.19624876976013184, 0.2386624813079834, 0.34200000762939453, 0.24213480949401855, 0.3536691665649414, 0.3394124209880829, 0.268436074256897, 0.0222016554325819, -0.015988627448678017, 0.20687270164489746, 0.22745203971862793, -0.07463880628347397, 0.26631784439086914, 0.248244047164917, 0.08215880393981934, 0.17291617393493652, 0.22389817237854004, 0.19687438011169434, 0.24387049674987793, 0.2648872435092926, 0.13712739944458008, 0.22476863861083984, 0.24156737327575684, 0.28035449981689453, 0.22596633434295654, 0.35265326499938965, 0.22101569175720215, 0.24511075019836426, 0.20929694175720215, 0.1341983526945114, 0.022324321791529655, 0.5098865032196045, 0.27878639101982117, 0.3634049892425537, 0.22358953952789307, 0.49420881271362305, 0.2150883674621582, 0.14793133735656738, 0.2724921703338623, 0.3035738468170166, -0.01506594754755497, 0.35437941551208496, 0.183027982711792, 0.32182908058166504, 0.2800009250640869, 0.210618257522583, 0.20503020286560059, 0.20439410209655762, 0.5724022388458252, 0.2687408924102783, 0.23231375217437744, 0.1844683289527893, 0.2240748405456543, 0.1953439712524414, 0.21173667907714844, 0.22333216667175293, 0.23993051052093506, 0.16630589962005615, 0.18453025817871094, 0.2539966106414795, 0.05576729774475098, 0.2528369426727295, 0.226515531539917, 0.12132994830608368, 0.1737041473388672, 0.23923659324645996, 0.2765970230102539, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907, 0.17680947482585907]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "url = \"http://seito.lavbic.net:5005/invocations\"\n",
    "\n",
    "# Load the test data\n",
    "X_test = np.load('X_test.npy', allow_pickle=True)\n",
    "\n",
    "# Select a single race (207 riders, 227 features)\n",
    "race_data = X_test[0]  # Shape should be (207, 227)\n",
    "print(f\"Input shape: {race_data.shape}\")  # Ensure it prints (207, 227)\n",
    "\n",
    "# Prepare the payload\n",
    "payload = {\n",
    "    \"instances\": race_data.tolist()  # Convert to list format\n",
    "}\n",
    "\n",
    "# Send the request\n",
    "try:\n",
    "    response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(payload), timeout=600)\n",
    "    if response.status_code == 200:\n",
    "        prediction = response.json()['predictions']\n",
    "        print(\"Prediction:\", prediction)\n",
    "    else:\n",
    "        print(\"Error:\", response.text)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Request failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                name    stage  index\n",
      "0    tour-down-under  stage-1      0\n",
      "1    tour-down-under  stage-2      1\n",
      "2    tour-down-under  stage-3      2\n",
      "3    tour-down-under  stage-4      3\n",
      "4    tour-down-under  stage-5      4\n",
      "..               ...      ...    ...\n",
      "148  tour-of-guangxi  stage-2    148\n",
      "149  tour-of-guangxi  stage-3    149\n",
      "150  tour-of-guangxi  stage-4    150\n",
      "151  tour-of-guangxi  stage-5    151\n",
      "152  tour-of-guangxi  stage-6    152\n",
      "\n",
      "[153 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the test data\n",
    "data = pd.read_csv('final_data.csv')\n",
    "\n",
    "# Retrieve race names of year 2024\n",
    "data_2024 = data[data['year'] == 2024]\n",
    "\n",
    "# Select unique names\n",
    "race_names_2024 = data_2024['name'].unique()\n",
    "\n",
    "# Split the data into format name, stage and index in array\n",
    "split_data = []\n",
    "for i, race_name in enumerate(race_names_2024):\n",
    "    names = race_name.split(' ')\n",
    "    name = names[0] \n",
    "    stage = names[1] \n",
    "    index = i\n",
    "    split_data.append([name, stage, index])\n",
    "\n",
    "# Convert to DataFrame\n",
    "split_df = pd.DataFrame(split_data, columns=['name', 'stage', 'index'])\n",
    "\n",
    "print(split_df)\n",
    "\n",
    "# Save as CSV\n",
    "split_df.to_csv('race_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name    stage  index\n",
      "0  Tour Down Under  Stage 1      0\n",
      "1  Tour Down Under  Stage 2      1\n",
      "2  Tour Down Under  Stage 3      2\n",
      "3  Tour Down Under  Stage 4      3\n",
      "4  Tour Down Under  Stage 5      4\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('race_names.csv')\n",
    "\n",
    "# replace - in name with ' ' and capitalize the first letter of each word\n",
    "data['name'] = data['name'].str.replace('-', ' ').str.title()\n",
    "\n",
    "# replace - in stage with ' ' and capitalize the first letter of each word\n",
    "data['stage'] = data['stage'].str.replace('-', ' ').str.title()\n",
    "\n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
