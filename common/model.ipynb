{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1160bd470>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pytorch\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1878, 207, 226)\n",
      "y_train shape: (1878, 207)\n",
      "X_test shape: (156, 207, 226)\n",
      "y_test shape: (156, 207)\n"
     ]
    }
   ],
   "source": [
    "# Load the data (adjust file paths as needed)\n",
    "X_train = np.load('X_train.npy', allow_pickle=True)\n",
    "y_train = np.load('y_train.npy', allow_pickle=True)\n",
    "X_test = np.load('X_test.npy', allow_pickle=True)\n",
    "y_test = np.load('y_test.npy', allow_pickle=True)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')  # Expected: (num_races_train, max_riders, num_features)\n",
    "print(f'y_train shape: {y_train.shape}')  # Expected: (num_races_train, max_riders)\n",
    "print(f'X_test shape: {X_test.shape}')    # Expected: (num_races_test, max_riders, num_features)\n",
    "print(f'y_test shape: {y_test.shape}')    # Expected: (num_races_test, max_riders)\n",
    "\n",
    "# Flatten the data for scikit-learn models\n",
    "X_train_flat = X_train.reshape(-1, X_train.shape[2])    # Shape: (num_races_train * max_riders, num_features)\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[2])       # Shape: (num_races_test * max_riders, num_features)\n",
    "\n",
    "# Flatten the targets\n",
    "y_train_flat = y_train.flatten()  # Shape: (num_races_train * max_riders,)\n",
    "y_test_flat = y_test.flatten()    # Shape: (num_races_test * max_riders,)\n",
    "\n",
    "# Filter out invalid targets (if necessary)\n",
    "valid_indices_train = y_train_flat > 0\n",
    "valid_indices_test = y_test_flat > 0\n",
    "\n",
    "X_train_flat = X_train_flat[valid_indices_train]\n",
    "y_train_flat = y_train_flat[valid_indices_train]\n",
    "\n",
    "X_test_flat = X_test_flat[valid_indices_test]\n",
    "y_test_flat = y_test_flat[valid_indices_test]\n",
    "\n",
    "# # Optionally scale the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_flat = scaler.fit_transform(X_train_flat)\n",
    "# X_test_flat = scaler.transform(X_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/tmp/mlartifacts/4', creation_time=1735895004824, experiment_id='4', last_update_time=1735895004824, lifecycle_stage='active', name='Race_Prediction_Experiment_I', tags={'mlflow.note.content': 'Here I use dataset that gives probability of winning '\n",
       "                        'to all riders'}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set MLflow experiment\n",
    "mlflow.set_tracking_uri(\"http://seito.lavbic.net:5000\")\n",
    "mlflow.set_experiment(\"Race_Prediction_Experiment_I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_class, param_grid, model_name, X_train, y_train, X_test, y_test):\n",
    "    from itertools import product\n",
    "    import pandas as pd\n",
    "\n",
    "    # Generate all combinations of hyperparameters\n",
    "    keys = param_grid.keys()\n",
    "    values = (param_grid[key] for key in keys)\n",
    "    param_combinations = [dict(zip(keys, combination)) for combination in product(*values)]\n",
    "\n",
    "    # For each combination, train and log the model\n",
    "    for idx, params in enumerate(param_combinations):\n",
    "        # Initialize model with current hyperparameters\n",
    "        model = model_class(**params)\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        smape = symmetric_mean_absolute_percentage_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Start MLflow run\n",
    "        with mlflow.start_run(run_name=f\"{model_name} - Run {idx+1}\"):\n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"model_class\", model_name)\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"test_mse\", mse)\n",
    "            mlflow.log_metric(\"test_mae\", mae)\n",
    "            mlflow.log_metric(\"test_r2\", r2)\n",
    "            mlflow.log_metric(\"test_mape\", mape)\n",
    "            mlflow.log_metric(\"test_rmse\", rmse)\n",
    "            mlflow.log_metric(\"test_smape\", smape)\n",
    "\n",
    "            # Log the model\n",
    "            input_example = X_train[:5]\n",
    "            signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                sk_model=model,\n",
    "                artifact_path=\"model\",\n",
    "                input_example=input_example,\n",
    "                signature=signature\n",
    "            )\n",
    "\n",
    "            # Print results\n",
    "            print(f\"\\n{model_name} Run {idx+1} parameters: {params}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test MSE: {mse:.4f}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test MAE: {mae:.4f}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test R^2 Score: {r2:.4f}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test MAPE: {mape:.4f}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test RMSE: {rmse:.4f}\")\n",
    "            print(f\"{model_name} Run {idx+1} Test sMAPE: {smape:.4f}\")\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    epsilon = 1e-8  # Small number to prevent division by zero\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Avoid division by zero\n",
    "    mask = np.abs(y_true) > epsilon\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.inf  # Return infinity if no valid entries\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    return mape\n",
    "\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    diff = np.abs(y_pred - y_true)\n",
    "    # Avoid division by zero\n",
    "    mask = denominator != 0\n",
    "    smape = np.mean((diff[mask] / denominator[mask])) * 100\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Run 1 parameters: {}\n",
      "Linear Regression Run 1 Test MSE: 0.1618\n",
      "Linear Regression Run 1 Test MAE: 0.3215\n",
      "Linear Regression Run 1 Test R^2 Score: -1.7566\n",
      "Linear Regression Run 1 Test MAPE: 93.7213\n",
      "Linear Regression Run 1 Test RMSE: 0.4022\n",
      "Linear Regression Run 1 Test sMAPE: 177.7054\n",
      "üèÉ View run Linear Regression - Run 1 at: http://seito.lavbic.net:5000/#/experiments/4/runs/38bf759288c8469f9a12dc1e7cf5dac1\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "linear_reg = LinearRegression\n",
    "param_grid_lr = {\n",
    "    # No hyperparameters to tune\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=linear_reg,\n",
    "    param_grid=param_grid_lr,\n",
    "    model_name=\"Linear Regression\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Regression Run 1 parameters: {'alpha': 0.1}\n",
      "Ridge Regression Run 1 Test MSE: 0.1618\n",
      "Ridge Regression Run 1 Test MAE: 0.3215\n",
      "Ridge Regression Run 1 Test R^2 Score: -1.7567\n",
      "Ridge Regression Run 1 Test MAPE: 93.7216\n",
      "Ridge Regression Run 1 Test RMSE: 0.4022\n",
      "Ridge Regression Run 1 Test sMAPE: 177.7063\n",
      "üèÉ View run Ridge Regression - Run 1 at: http://seito.lavbic.net:5000/#/experiments/4/runs/91a649f0356945fb9285449e1895f52c\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Ridge Regression Run 2 parameters: {'alpha': 0.9}\n",
      "Ridge Regression Run 2 Test MSE: 0.1618\n",
      "Ridge Regression Run 2 Test MAE: 0.3215\n",
      "Ridge Regression Run 2 Test R^2 Score: -1.7567\n",
      "Ridge Regression Run 2 Test MAPE: 93.7244\n",
      "Ridge Regression Run 2 Test RMSE: 0.4022\n",
      "Ridge Regression Run 2 Test sMAPE: 177.7144\n",
      "üèÉ View run Ridge Regression - Run 2 at: http://seito.lavbic.net:5000/#/experiments/4/runs/ee048c5643be40b98c1981641f1940f3\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Ridge Regression Run 3 parameters: {'alpha': 1.0}\n",
      "Ridge Regression Run 3 Test MSE: 0.1618\n",
      "Ridge Regression Run 3 Test MAE: 0.3215\n",
      "Ridge Regression Run 3 Test R^2 Score: -1.7567\n",
      "Ridge Regression Run 3 Test MAPE: 93.7247\n",
      "Ridge Regression Run 3 Test RMSE: 0.4022\n",
      "Ridge Regression Run 3 Test sMAPE: 177.7154\n",
      "üèÉ View run Ridge Regression - Run 3 at: http://seito.lavbic.net:5000/#/experiments/4/runs/a15fc77eb6f04b0abd6b899e162ae5f6\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Ridge Regression Run 4 parameters: {'alpha': 1.5}\n",
      "Ridge Regression Run 4 Test MSE: 0.1618\n",
      "Ridge Regression Run 4 Test MAE: 0.3215\n",
      "Ridge Regression Run 4 Test R^2 Score: -1.7568\n",
      "Ridge Regression Run 4 Test MAPE: 93.7265\n",
      "Ridge Regression Run 4 Test RMSE: 0.4022\n",
      "Ridge Regression Run 4 Test sMAPE: 177.7207\n",
      "üèÉ View run Ridge Regression - Run 4 at: http://seito.lavbic.net:5000/#/experiments/4/runs/2706acb3ffcc49599edc226fa1b516ca\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Ridge Regression Run 5 parameters: {'alpha': 2.0}\n",
      "Ridge Regression Run 5 Test MSE: 0.1618\n",
      "Ridge Regression Run 5 Test MAE: 0.3215\n",
      "Ridge Regression Run 5 Test R^2 Score: -1.7568\n",
      "Ridge Regression Run 5 Test MAPE: 93.7283\n",
      "Ridge Regression Run 5 Test RMSE: 0.4022\n",
      "Ridge Regression Run 5 Test sMAPE: 177.7259\n",
      "üèÉ View run Ridge Regression - Run 5 at: http://seito.lavbic.net:5000/#/experiments/4/runs/c13bc111a2694223b2dd9aa455317fcf\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Ridge Regression Run 6 parameters: {'alpha': 10.0}\n",
      "Ridge Regression Run 6 Test MSE: 0.1618\n",
      "Ridge Regression Run 6 Test MAE: 0.3216\n",
      "Ridge Regression Run 6 Test R^2 Score: -1.7575\n",
      "Ridge Regression Run 6 Test MAPE: 93.7559\n",
      "Ridge Regression Run 6 Test RMSE: 0.4023\n",
      "Ridge Regression Run 6 Test sMAPE: 177.8086\n",
      "üèÉ View run Ridge Regression - Run 6 at: http://seito.lavbic.net:5000/#/experiments/4/runs/293bd70d77ea4ea6bcc79180d8ef730d\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "ridge_reg = Ridge\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 0.9, 1.0, 1.5, 2.0, 10.0]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=ridge_reg,\n",
    "    param_grid=param_grid_ridge,\n",
    "    model_name=\"Ridge Regression\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Run 1 parameters: {'alpha': 0.0001, 'max_iter': 10000}\n",
      "Lasso Regression Run 1 Test MSE: 0.1637\n",
      "Lasso Regression Run 1 Test MAE: 0.3243\n",
      "Lasso Regression Run 1 Test R^2 Score: -1.7900\n",
      "Lasso Regression Run 1 Test MAPE: 95.0636\n",
      "Lasso Regression Run 1 Test RMSE: 0.4047\n",
      "Lasso Regression Run 1 Test sMAPE: 182.0153\n",
      "üèÉ View run Lasso Regression - Run 1 at: http://seito.lavbic.net:5000/#/experiments/4/runs/41d2885734194994b05dd3498e326a29\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Lasso Regression Run 2 parameters: {'alpha': 0.001, 'max_iter': 10000}\n",
      "Lasso Regression Run 2 Test MSE: 0.1658\n",
      "Lasso Regression Run 2 Test MAE: 0.3272\n",
      "Lasso Regression Run 2 Test R^2 Score: -1.8244\n",
      "Lasso Regression Run 2 Test MAPE: 96.6071\n",
      "Lasso Regression Run 2 Test RMSE: 0.4071\n",
      "Lasso Regression Run 2 Test sMAPE: 187.0969\n",
      "üèÉ View run Lasso Regression - Run 2 at: http://seito.lavbic.net:5000/#/experiments/4/runs/f9f0f1c0b26840af959643bccb3f2711\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Lasso Regression Run 3 parameters: {'alpha': 0.01, 'max_iter': 10000}\n",
      "Lasso Regression Run 3 Test MSE: 0.1658\n",
      "Lasso Regression Run 3 Test MAE: 0.3273\n",
      "Lasso Regression Run 3 Test R^2 Score: -1.8247\n",
      "Lasso Regression Run 3 Test MAPE: 96.6251\n",
      "Lasso Regression Run 3 Test RMSE: 0.4072\n",
      "Lasso Regression Run 3 Test sMAPE: 187.1598\n",
      "üèÉ View run Lasso Regression - Run 3 at: http://seito.lavbic.net:5000/#/experiments/4/runs/ceca75754d914cf4aaf42c130d3da173\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Lasso Regression Run 4 parameters: {'alpha': 0.1, 'max_iter': 10000}\n",
      "Lasso Regression Run 4 Test MSE: 0.1657\n",
      "Lasso Regression Run 4 Test MAE: 0.3272\n",
      "Lasso Regression Run 4 Test R^2 Score: -1.8238\n",
      "Lasso Regression Run 4 Test MAPE: 96.5803\n",
      "Lasso Regression Run 4 Test RMSE: 0.4071\n",
      "Lasso Regression Run 4 Test sMAPE: 186.9961\n",
      "üèÉ View run Lasso Regression - Run 4 at: http://seito.lavbic.net:5000/#/experiments/4/runs/3c306ac64cad4667a33632b0ed72ad61\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Lasso Regression Run 5 parameters: {'alpha': 1.0, 'max_iter': 10000}\n",
      "Lasso Regression Run 5 Test MSE: 0.1657\n",
      "Lasso Regression Run 5 Test MAE: 0.3272\n",
      "Lasso Regression Run 5 Test R^2 Score: -1.8238\n",
      "Lasso Regression Run 5 Test MAPE: 96.5803\n",
      "Lasso Regression Run 5 Test RMSE: 0.4071\n",
      "Lasso Regression Run 5 Test sMAPE: 186.9961\n",
      "üèÉ View run Lasso Regression - Run 5 at: http://seito.lavbic.net:5000/#/experiments/4/runs/3d836c5d90aa49d985ab64c8b4c8faf0\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Lasso Regression Run 6 parameters: {'alpha': 1.5, 'max_iter': 10000}\n",
      "Lasso Regression Run 6 Test MSE: 0.1657\n",
      "Lasso Regression Run 6 Test MAE: 0.3272\n",
      "Lasso Regression Run 6 Test R^2 Score: -1.8238\n",
      "Lasso Regression Run 6 Test MAPE: 96.5803\n",
      "Lasso Regression Run 6 Test RMSE: 0.4071\n",
      "Lasso Regression Run 6 Test sMAPE: 186.9961\n",
      "üèÉ View run Lasso Regression - Run 6 at: http://seito.lavbic.net:5000/#/experiments/4/runs/d96c069874fd46868b092008ed888c9d\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Lasso Regression Run 7 parameters: {'alpha': 2.0, 'max_iter': 10000}\n",
      "Lasso Regression Run 7 Test MSE: 0.1657\n",
      "Lasso Regression Run 7 Test MAE: 0.3272\n",
      "Lasso Regression Run 7 Test R^2 Score: -1.8238\n",
      "Lasso Regression Run 7 Test MAPE: 96.5803\n",
      "Lasso Regression Run 7 Test RMSE: 0.4071\n",
      "Lasso Regression Run 7 Test sMAPE: 186.9961\n",
      "üèÉ View run Lasso Regression - Run 7 at: http://seito.lavbic.net:5000/#/experiments/4/runs/e7a424652c4a400284dc404c7ce57fe7\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Lasso Regression Run 8 parameters: {'alpha': 10.0, 'max_iter': 10000}\n",
      "Lasso Regression Run 8 Test MSE: 0.1657\n",
      "Lasso Regression Run 8 Test MAE: 0.3272\n",
      "Lasso Regression Run 8 Test R^2 Score: -1.8238\n",
      "Lasso Regression Run 8 Test MAPE: 96.5803\n",
      "Lasso Regression Run 8 Test RMSE: 0.4071\n",
      "Lasso Regression Run 8 Test sMAPE: 186.9961\n",
      "üèÉ View run Lasso Regression - Run 8 at: http://seito.lavbic.net:5000/#/experiments/4/runs/2cf5eed0f3c849ddac293455c6d548ea\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "lasso_reg = Lasso\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 1.5, 2.0, 10.0],\n",
    "    'max_iter': [10000]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=lasso_reg,\n",
    "    param_grid=param_grid_lasso,\n",
    "    model_name=\"Lasso Regression\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Regressor Run 1 parameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "Decision Tree Regressor Run 1 Test MSE: 0.1590\n",
      "Decision Tree Regressor Run 1 Test MAE: 0.3170\n",
      "Decision Tree Regressor Run 1 Test R^2 Score: -1.7090\n",
      "Decision Tree Regressor Run 1 Test MAPE: 94.9518\n",
      "Decision Tree Regressor Run 1 Test RMSE: 0.3987\n",
      "Decision Tree Regressor Run 1 Test sMAPE: 182.0125\n",
      "üèÉ View run Decision Tree Regressor - Run 1 at: http://seito.lavbic.net:5000/#/experiments/4/runs/64ee1719c3d0406ba1945fd03399e72d\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 2 parameters: {'max_depth': None, 'min_samples_split': 5}\n",
      "Decision Tree Regressor Run 2 Test MSE: 0.1595\n",
      "Decision Tree Regressor Run 2 Test MAE: 0.3182\n",
      "Decision Tree Regressor Run 2 Test R^2 Score: -1.7172\n",
      "Decision Tree Regressor Run 2 Test MAPE: 94.6744\n",
      "Decision Tree Regressor Run 2 Test RMSE: 0.3993\n",
      "Decision Tree Regressor Run 2 Test sMAPE: 182.0821\n",
      "üèÉ View run Decision Tree Regressor - Run 2 at: http://seito.lavbic.net:5000/#/experiments/4/runs/138698662a29475293e39ba6bf5a2f7b\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 3 parameters: {'max_depth': None, 'min_samples_split': 10}\n",
      "Decision Tree Regressor Run 3 Test MSE: 0.1585\n",
      "Decision Tree Regressor Run 3 Test MAE: 0.3167\n",
      "Decision Tree Regressor Run 3 Test R^2 Score: -1.7004\n",
      "Decision Tree Regressor Run 3 Test MAPE: 93.9209\n",
      "Decision Tree Regressor Run 3 Test RMSE: 0.3981\n",
      "Decision Tree Regressor Run 3 Test sMAPE: 179.6509\n",
      "üèÉ View run Decision Tree Regressor - Run 3 at: http://seito.lavbic.net:5000/#/experiments/4/runs/1b31990eda6142e6b0c1ad132fb5e6f0\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 4 parameters: {'max_depth': 5, 'min_samples_split': 2}\n",
      "Decision Tree Regressor Run 4 Test MSE: 0.1586\n",
      "Decision Tree Regressor Run 4 Test MAE: 0.3178\n",
      "Decision Tree Regressor Run 4 Test R^2 Score: -1.7025\n",
      "Decision Tree Regressor Run 4 Test MAPE: 92.5154\n",
      "Decision Tree Regressor Run 4 Test RMSE: 0.3983\n",
      "Decision Tree Regressor Run 4 Test sMAPE: 175.6622\n",
      "üèÉ View run Decision Tree Regressor - Run 4 at: http://seito.lavbic.net:5000/#/experiments/4/runs/f3dcbffa1c0649a9ab0961a48b52478f\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 5 parameters: {'max_depth': 5, 'min_samples_split': 5}\n",
      "Decision Tree Regressor Run 5 Test MSE: 0.1586\n",
      "Decision Tree Regressor Run 5 Test MAE: 0.3178\n",
      "Decision Tree Regressor Run 5 Test R^2 Score: -1.7025\n",
      "Decision Tree Regressor Run 5 Test MAPE: 92.5154\n",
      "Decision Tree Regressor Run 5 Test RMSE: 0.3983\n",
      "Decision Tree Regressor Run 5 Test sMAPE: 175.6622\n",
      "üèÉ View run Decision Tree Regressor - Run 5 at: http://seito.lavbic.net:5000/#/experiments/4/runs/188418cb3be243a4827de3b9ee62551e\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 6 parameters: {'max_depth': 5, 'min_samples_split': 10}\n",
      "Decision Tree Regressor Run 6 Test MSE: 0.1586\n",
      "Decision Tree Regressor Run 6 Test MAE: 0.3178\n",
      "Decision Tree Regressor Run 6 Test R^2 Score: -1.7025\n",
      "Decision Tree Regressor Run 6 Test MAPE: 92.5154\n",
      "Decision Tree Regressor Run 6 Test RMSE: 0.3983\n",
      "Decision Tree Regressor Run 6 Test sMAPE: 175.6622\n",
      "üèÉ View run Decision Tree Regressor - Run 6 at: http://seito.lavbic.net:5000/#/experiments/4/runs/16040a9dc1404be2b8ec3c88e08cf654\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 7 parameters: {'max_depth': 10, 'min_samples_split': 2}\n",
      "Decision Tree Regressor Run 7 Test MSE: 0.1593\n",
      "Decision Tree Regressor Run 7 Test MAE: 0.3184\n",
      "Decision Tree Regressor Run 7 Test R^2 Score: -1.7140\n",
      "Decision Tree Regressor Run 7 Test MAPE: 92.7819\n",
      "Decision Tree Regressor Run 7 Test RMSE: 0.3991\n",
      "Decision Tree Regressor Run 7 Test sMAPE: 175.6730\n",
      "üèÉ View run Decision Tree Regressor - Run 7 at: http://seito.lavbic.net:5000/#/experiments/4/runs/4e1c77828e094b428635e8897121f003\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 8 parameters: {'max_depth': 10, 'min_samples_split': 5}\n",
      "Decision Tree Regressor Run 8 Test MSE: 0.1579\n",
      "Decision Tree Regressor Run 8 Test MAE: 0.3167\n",
      "Decision Tree Regressor Run 8 Test R^2 Score: -1.6911\n",
      "Decision Tree Regressor Run 8 Test MAPE: 92.5391\n",
      "Decision Tree Regressor Run 8 Test RMSE: 0.3974\n",
      "Decision Tree Regressor Run 8 Test sMAPE: 175.1097\n",
      "üèÉ View run Decision Tree Regressor - Run 8 at: http://seito.lavbic.net:5000/#/experiments/4/runs/5c945d81b9714afcb39d4418279fc757\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 9 parameters: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Decision Tree Regressor Run 9 Test MSE: 0.1579\n",
      "Decision Tree Regressor Run 9 Test MAE: 0.3167\n",
      "Decision Tree Regressor Run 9 Test R^2 Score: -1.6912\n",
      "Decision Tree Regressor Run 9 Test MAPE: 92.5740\n",
      "Decision Tree Regressor Run 9 Test RMSE: 0.3974\n",
      "Decision Tree Regressor Run 9 Test sMAPE: 175.2200\n",
      "üèÉ View run Decision Tree Regressor - Run 9 at: http://seito.lavbic.net:5000/#/experiments/4/runs/a36ff740294040a98668a125c708e747\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 10 parameters: {'max_depth': 20, 'min_samples_split': 2}\n",
      "Decision Tree Regressor Run 10 Test MSE: 0.1626\n",
      "Decision Tree Regressor Run 10 Test MAE: 0.3230\n",
      "Decision Tree Regressor Run 10 Test R^2 Score: -1.7699\n",
      "Decision Tree Regressor Run 10 Test MAPE: 96.0381\n",
      "Decision Tree Regressor Run 10 Test RMSE: 0.4032\n",
      "Decision Tree Regressor Run 10 Test sMAPE: 180.8578\n",
      "üèÉ View run Decision Tree Regressor - Run 10 at: http://seito.lavbic.net:5000/#/experiments/4/runs/27e9949dc49e4e9985a8ca60a975dfb5\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 11 parameters: {'max_depth': 20, 'min_samples_split': 5}\n",
      "Decision Tree Regressor Run 11 Test MSE: 0.1607\n",
      "Decision Tree Regressor Run 11 Test MAE: 0.3200\n",
      "Decision Tree Regressor Run 11 Test R^2 Score: -1.7388\n",
      "Decision Tree Regressor Run 11 Test MAPE: 94.5126\n",
      "Decision Tree Regressor Run 11 Test RMSE: 0.4009\n",
      "Decision Tree Regressor Run 11 Test sMAPE: 178.9694\n",
      "üèÉ View run Decision Tree Regressor - Run 11 at: http://seito.lavbic.net:5000/#/experiments/4/runs/d036475fa4744d8d806c686bf33ec34c\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "Decision Tree Regressor Run 12 parameters: {'max_depth': 20, 'min_samples_split': 10}\n",
      "Decision Tree Regressor Run 12 Test MSE: 0.1607\n",
      "Decision Tree Regressor Run 12 Test MAE: 0.3202\n",
      "Decision Tree Regressor Run 12 Test R^2 Score: -1.7381\n",
      "Decision Tree Regressor Run 12 Test MAPE: 94.7730\n",
      "Decision Tree Regressor Run 12 Test RMSE: 0.4009\n",
      "Decision Tree Regressor Run 12 Test sMAPE: 179.5406\n",
      "üèÉ View run Decision Tree Regressor - Run 12 at: http://seito.lavbic.net:5000/#/experiments/4/runs/80e8c06ab914491d988141aeb6b90c5e\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "decision_tree_reg = DecisionTreeRegressor\n",
    "param_grid_dtree_reg = {\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=decision_tree_reg,\n",
    "    param_grid=param_grid_dtree_reg,\n",
    "    model_name=\"Decision Tree Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model_class = SVR\n",
    "param_grid_svr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'epsilon': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=svr_model_class,\n",
    "    param_grid=param_grid_svr,\n",
    "    model_name=\"Support Vector Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reg = RandomForestRegressor()\n",
    "param_grid_rf_reg = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model=random_forest_reg,\n",
    "    param_grid=param_grid_rf_reg,\n",
    "    model_name=\"Random Forest Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "gb_regressor = GradientBoostingRegressor()\n",
    "param_grid_gb_reg = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model=gb_regressor,\n",
    "    param_grid=param_grid_gb_reg,\n",
    "    model_name=\"Gradient Boosting Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Regressor Run 1 parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 3, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 1 Test MSE: 0.1628\n",
      "XGBoost Regressor Run 1 Test MAE: 0.3230\n",
      "XGBoost Regressor Run 1 Test R^2 Score: -1.7747\n",
      "XGBoost Regressor Run 1 Test MAPE: 94.4042\n",
      "XGBoost Regressor Run 1 Test RMSE: 0.4035\n",
      "XGBoost Regressor Run 1 Test sMAPE: 180.5093\n",
      "üèÉ View run XGBoost Regressor - Run 1 at: http://seito.lavbic.net:5000/#/experiments/4/runs/ef7e89ad95174dafa6bc99e25d015468\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "XGBoost Regressor Run 2 parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 5, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 2 Test MSE: 0.1619\n",
      "XGBoost Regressor Run 2 Test MAE: 0.3212\n",
      "XGBoost Regressor Run 2 Test R^2 Score: -1.7579\n",
      "XGBoost Regressor Run 2 Test MAPE: 93.2760\n",
      "XGBoost Regressor Run 2 Test RMSE: 0.4023\n",
      "XGBoost Regressor Run 2 Test sMAPE: 177.7786\n",
      "üèÉ View run XGBoost Regressor - Run 2 at: http://seito.lavbic.net:5000/#/experiments/4/runs/ac742afcc3fa4ead8c1bbc0bc6725a20\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "XGBoost Regressor Run 3 parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 3 Test MSE: 0.1600\n",
      "XGBoost Regressor Run 3 Test MAE: 0.3187\n",
      "XGBoost Regressor Run 3 Test R^2 Score: -1.7256\n",
      "XGBoost Regressor Run 3 Test MAPE: 92.1867\n",
      "XGBoost Regressor Run 3 Test RMSE: 0.4000\n",
      "XGBoost Regressor Run 3 Test sMAPE: 174.5770\n",
      "üèÉ View run XGBoost Regressor - Run 3 at: http://seito.lavbic.net:5000/#/experiments/4/runs/12888efbc68e4e789b2fd4835c415fec\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "XGBoost Regressor Run 4 parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 5, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 4 Test MSE: 0.1586\n",
      "XGBoost Regressor Run 4 Test MAE: 0.3165\n",
      "XGBoost Regressor Run 4 Test R^2 Score: -1.7028\n",
      "XGBoost Regressor Run 4 Test MAPE: 91.1038\n",
      "XGBoost Regressor Run 4 Test RMSE: 0.3983\n",
      "XGBoost Regressor Run 4 Test sMAPE: 171.5409\n",
      "üèÉ View run XGBoost Regressor - Run 4 at: http://seito.lavbic.net:5000/#/experiments/4/runs/f0aaa1ee85264b6fb9363de940ea2589\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "XGBoost Regressor Run 5 parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 3, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 5 Test MSE: 0.1617\n",
      "XGBoost Regressor Run 5 Test MAE: 0.3213\n",
      "XGBoost Regressor Run 5 Test R^2 Score: -1.7555\n",
      "XGBoost Regressor Run 5 Test MAPE: 93.5574\n",
      "XGBoost Regressor Run 5 Test RMSE: 0.4022\n",
      "XGBoost Regressor Run 5 Test sMAPE: 178.2792\n",
      "üèÉ View run XGBoost Regressor - Run 5 at: http://seito.lavbic.net:5000/#/experiments/4/runs/dd1032b8494b4ec0a1f84848b4c9b18e\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "XGBoost Regressor Run 6 parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 5, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 6 Test MSE: 0.1602\n",
      "XGBoost Regressor Run 6 Test MAE: 0.3188\n",
      "XGBoost Regressor Run 6 Test R^2 Score: -1.7300\n",
      "XGBoost Regressor Run 6 Test MAPE: 92.1071\n",
      "XGBoost Regressor Run 6 Test RMSE: 0.4003\n",
      "XGBoost Regressor Run 6 Test sMAPE: 174.8667\n",
      "üèÉ View run XGBoost Regressor - Run 6 at: http://seito.lavbic.net:5000/#/experiments/4/runs/b980e310f96d477fa60d0fd933fde46a\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "XGBoost Regressor Run 7 parameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 7 Test MSE: 0.1592\n",
      "XGBoost Regressor Run 7 Test MAE: 0.3174\n",
      "XGBoost Regressor Run 7 Test R^2 Score: -1.7130\n",
      "XGBoost Regressor Run 7 Test MAPE: 91.4098\n",
      "XGBoost Regressor Run 7 Test RMSE: 0.3990\n",
      "XGBoost Regressor Run 7 Test sMAPE: 172.7867\n",
      "üèÉ View run XGBoost Regressor - Run 7 at: http://seito.lavbic.net:5000/#/experiments/4/runs/28cee76728594f8ea15435b2151e6323\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n",
      "\n",
      "XGBoost Regressor Run 8 parameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 5, 'objective': 'reg:squarederror'}\n",
      "XGBoost Regressor Run 8 Test MSE: 0.1582\n",
      "XGBoost Regressor Run 8 Test MAE: 0.3157\n",
      "XGBoost Regressor Run 8 Test R^2 Score: -1.6960\n",
      "XGBoost Regressor Run 8 Test MAPE: 90.5989\n",
      "XGBoost Regressor Run 8 Test RMSE: 0.3978\n",
      "XGBoost Regressor Run 8 Test sMAPE: 170.1646\n",
      "üèÉ View run XGBoost Regressor - Run 8 at: http://seito.lavbic.net:5000/#/experiments/4/runs/fe1d41831f2449db9529cb9a4d260ffd\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "xgboost_reg = xgb.XGBRegressor\n",
    "param_grid_xgb_reg = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=xgboost_reg,\n",
    "    param_grid=param_grid_xgb_reg,\n",
    "    model_name=\"XGBoost Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_and_evaluate_model() got an unexpected keyword argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m lgbm_reg \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor()\n\u001b[1;32m      2\u001b[0m param_grid_lgbm_reg \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m63\u001b[39m]\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlgbm_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_grid_lgbm_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLightGBM Regressor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test_flat\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_and_evaluate_model() got an unexpected keyword argument 'model'"
     ]
    }
   ],
   "source": [
    "lgbm_reg = lgb.LGBMRegressor()\n",
    "param_grid_lgbm_reg = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'num_leaves': [31, 63]\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model=lgbm_reg,\n",
    "    param_grid=param_grid_lgbm_reg,\n",
    "    model_name=\"LightGBM Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_model = KNeighborsRegressor\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "train_and_evaluate_model(\n",
    "    model_class=knn_model,\n",
    "    param_grid=param_grid_knn,\n",
    "    model_name=\"K-Nearest Neighbors Regressor\",\n",
    "    X_train=X_train_flat,\n",
    "    y_train=y_train_flat,\n",
    "    X_test=X_test_flat,\n",
    "    y_test=y_test_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128):\n",
    "        super(RaceRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)  # Output a score for each rider\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x should have shape (batch_size, num_features)\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RaceRegressionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)  # Shape: (num_samples, num_features)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)  # Shape: (num_samples,)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        return X, y\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = RaceRegressionDataset(X_train_flat, y_train_flat)\n",
    "test_dataset = RaceRegressionDataset(X_test_flat, y_test_flat)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:40:19,682] A new study created in memory with name: no-name-8228b0c5-10ec-42c6-a8d9-f35628983cb4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 0 at: http://seito.lavbic.net:5000/#/experiments/4/runs/527b121e2d5a4b48ba859fa56ca56e14\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:42:36,712] Trial 0 finished with value: 0.3253335654735565 and parameters: {'hidden_size': 64, 'learning_rate': 0.0038181832497221845, 'weight_decay': 0.0009309059726738406, 'num_epochs': 30, 'batch_size': 64}. Best is trial 0 with value: 0.3253335654735565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 1 at: http://seito.lavbic.net:5000/#/experiments/4/runs/5aa453d9797840cd8929538a5c7bea5e\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:43:36,175] Trial 1 finished with value: 0.3204706907272339 and parameters: {'hidden_size': 128, 'learning_rate': 0.0028833908822931283, 'weight_decay': 0.00040864350506258755, 'num_epochs': 14, 'batch_size': 128}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 2 at: http://seito.lavbic.net:5000/#/experiments/4/runs/12294f1ae32349e79edd8ae4980a9038\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:44:21,319] Trial 2 finished with value: 0.32630306482315063 and parameters: {'hidden_size': 64, 'learning_rate': 0.00785538963090699, 'weight_decay': 0.0007680363568646919, 'num_epochs': 12, 'batch_size': 128}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 3 at: http://seito.lavbic.net:5000/#/experiments/4/runs/537fea48ce0047cfa1a2d23a44a01b2e\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:45:11,028] Trial 3 finished with value: 0.32895562052726746 and parameters: {'hidden_size': 128, 'learning_rate': 0.00408106112319998, 'weight_decay': 0.0008897283681849604, 'num_epochs': 11, 'batch_size': 128}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 4 at: http://seito.lavbic.net:5000/#/experiments/4/runs/e3ffe9bc45f445a7bd9ba196e839a976\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:47:00,593] Trial 4 finished with value: 0.32614192366600037 and parameters: {'hidden_size': 256, 'learning_rate': 0.009848600962941807, 'weight_decay': 0.0008633443110505931, 'num_epochs': 17, 'batch_size': 64}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 5 at: http://seito.lavbic.net:5000/#/experiments/4/runs/f021e7e14ff449e38056c0651b9945c2\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:48:52,403] Trial 5 finished with value: 0.3238430917263031 and parameters: {'hidden_size': 64, 'learning_rate': 0.0051290145739180375, 'weight_decay': 0.0006425034283196932, 'num_epochs': 25, 'batch_size': 64}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 6 at: http://seito.lavbic.net:5000/#/experiments/4/runs/71ee353fbab54aa39021786854239f57\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:50:11,297] Trial 6 finished with value: 0.3292449116706848 and parameters: {'hidden_size': 256, 'learning_rate': 0.009808735964720072, 'weight_decay': 0.0008953525324006488, 'num_epochs': 16, 'batch_size': 256}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 7 at: http://seito.lavbic.net:5000/#/experiments/4/runs/18884fed7e5c4c04b94c3e563949e157\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:52:07,221] Trial 7 finished with value: 0.3324184715747833 and parameters: {'hidden_size': 256, 'learning_rate': 0.009656069433829363, 'weight_decay': 0.0002552301728680728, 'num_epochs': 22, 'batch_size': 128}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 8 at: http://seito.lavbic.net:5000/#/experiments/4/runs/579701abe9da4e169aed5ea63f066cf1\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:54:37,440] Trial 8 finished with value: 0.3264789879322052 and parameters: {'hidden_size': 128, 'learning_rate': 0.004586570013095813, 'weight_decay': 0.0009255731673483957, 'num_epochs': 30, 'batch_size': 64}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 9 at: http://seito.lavbic.net:5000/#/experiments/4/runs/152aee4688a54c7c83610afc8aa59008\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:56:48,415] Trial 9 finished with value: 0.32840102910995483 and parameters: {'hidden_size': 256, 'learning_rate': 0.0042817375472470965, 'weight_decay': 0.00045094601835331434, 'num_epochs': 28, 'batch_size': 256}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 10 at: http://seito.lavbic.net:5000/#/experiments/4/runs/e5c6594abf734c87abca73cf21a4acec\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:57:55,544] Trial 10 finished with value: 0.3819810450077057 and parameters: {'hidden_size': 128, 'learning_rate': 0.00026459164187032924, 'weight_decay': 3.4473701396331945e-05, 'num_epochs': 16, 'batch_size': 128}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 11 at: http://seito.lavbic.net:5000/#/experiments/4/runs/59a3be7ca97e438bbb519cedc7bd2607\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 14:59:40,449] Trial 11 finished with value: 0.32689985632896423 and parameters: {'hidden_size': 64, 'learning_rate': 0.0017658020016613231, 'weight_decay': 0.0005970264487940333, 'num_epochs': 23, 'batch_size': 64}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 12 at: http://seito.lavbic.net:5000/#/experiments/4/runs/b9b4a0f9f02d4b24a350b7f7f6d96b23\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 15:01:07,036] Trial 12 finished with value: 0.32614657282829285 and parameters: {'hidden_size': 64, 'learning_rate': 0.0066376137666176935, 'weight_decay': 0.0004918678677327703, 'num_epochs': 25, 'batch_size': 128}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 13 at: http://seito.lavbic.net:5000/#/experiments/4/runs/968ec9047ac9459aaa909e29f23171f2\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 15:02:44,407] Trial 13 finished with value: 0.3311288356781006 and parameters: {'hidden_size': 128, 'learning_rate': 0.002342756114719668, 'weight_decay': 0.0006227813044189284, 'num_epochs': 19, 'batch_size': 64}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 14 at: http://seito.lavbic.net:5000/#/experiments/4/runs/9ce7ed551a8943d0a16c80cd855ce7da\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 15:04:20,670] Trial 14 finished with value: 0.32637375593185425 and parameters: {'hidden_size': 128, 'learning_rate': 0.006194079499362755, 'weight_decay': 0.0003189742816038599, 'num_epochs': 26, 'batch_size': 256}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 15 at: http://seito.lavbic.net:5000/#/experiments/4/runs/f848a2bb4720439f8da5924f21eddccf\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 15:05:15,196] Trial 15 finished with value: 0.32537612318992615 and parameters: {'hidden_size': 64, 'learning_rate': 0.0026872108867184853, 'weight_decay': 0.0003108427918928884, 'num_epochs': 14, 'batch_size': 128}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 16 at: http://seito.lavbic.net:5000/#/experiments/4/runs/d40480d90be54829afa08d77ee95e632\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 15:06:49,116] Trial 16 finished with value: 0.3264787495136261 and parameters: {'hidden_size': 64, 'learning_rate': 0.005895901172089804, 'weight_decay': 0.0006990752336681676, 'num_epochs': 20, 'batch_size': 64}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 17 at: http://seito.lavbic.net:5000/#/experiments/4/runs/77bc40c4cdf74a8d9872d8e5133ac568\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 15:07:43,326] Trial 17 finished with value: 0.39042773842811584 and parameters: {'hidden_size': 128, 'learning_rate': 0.0005344395611382559, 'weight_decay': 0.0001341824980020613, 'num_epochs': 10, 'batch_size': 64}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 18 at: http://seito.lavbic.net:5000/#/experiments/4/runs/083688292a9241b9b440ca679bdfa4dc\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 15:09:05,903] Trial 18 finished with value: 0.329637736082077 and parameters: {'hidden_size': 64, 'learning_rate': 0.003233552172718639, 'weight_decay': 0.00041751547334680113, 'num_epochs': 23, 'batch_size': 128}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Neural Network MAE Run 19 at: http://seito.lavbic.net:5000/#/experiments/4/runs/30395ace6d524bbb86ef1a7679a420e4\n",
      "üß™ View experiment at: http://seito.lavbic.net:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 15:09:57,773] Trial 19 finished with value: 0.32670921087265015 and parameters: {'hidden_size': 128, 'learning_rate': 0.007904700844140376, 'weight_decay': 0.0005954314297899467, 'num_epochs': 13, 'batch_size': 256}. Best is trial 1 with value: 0.3204706907272339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'hidden_size': 128, 'learning_rate': 0.0028833908822931283, 'weight_decay': 0.00040864350506258755, 'num_epochs': 14, 'batch_size': 128}\n",
      "Best sMAPE: 0.3204706907272339\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameter suggestions\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [64, 128, 256])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 10, 30)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [64, 128, 256])\n",
    "\n",
    "    # Create data loaders with the suggested batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    input_size = X_train_flat.shape[1]\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = RaceRegressionModel(input_size, hidden_size).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=f\"Neural Network MAE Run {trial.number}\"):\n",
    "        mlflow.log_params({\n",
    "            'model_class': 'RaceRegressionModel',\n",
    "            'hidden_size': hidden_size,\n",
    "            'learning_rate': learning_rate,\n",
    "            'weight_decay': weight_decay,\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size\n",
    "        })\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "            average_loss = total_loss / len(train_loader.dataset)\n",
    "            mlflow.log_metric(\"train_loss\", average_loss, step=epoch)\n",
    "\n",
    "        # Evaluation on test set\n",
    "        model.eval()\n",
    "        y_true_list = []\n",
    "        y_pred_list = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                outputs = model(X_batch)\n",
    "                y_true_list.extend(y_batch.cpu().numpy())\n",
    "                y_pred_list.extend(outputs.cpu().numpy())\n",
    "\n",
    "        y_true_array = np.array(y_true_list)\n",
    "        y_pred_array = np.array(y_pred_list)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        mse = mean_squared_error(y_true_array, y_pred_array)\n",
    "        mae = mean_absolute_error(y_true_array, y_pred_array)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_true_array, y_pred_array)\n",
    "        mape = mean_absolute_percentage_error(y_true_array, y_pred_array)\n",
    "        smape = symmetric_mean_absolute_percentage_error(y_true_array, y_pred_array)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            'test_mse': mse,\n",
    "            'test_mae': mae,\n",
    "            'test_rmse': rmse,\n",
    "            'test_r2': r2,\n",
    "            'test_mape': mape,\n",
    "            'test_smape': smape\n",
    "        })\n",
    "\n",
    "        # Log the model\n",
    "        input_example = X_train_flat[:5].astype(np.float32)\n",
    "        input_example_tensor = torch.tensor(input_example, dtype=torch.float32).to(device)\n",
    "        signature = infer_signature(\n",
    "            input_example,\n",
    "            model(input_example_tensor).cpu().detach().numpy()\n",
    "        )\n",
    "        mlflow.pytorch.log_model(\n",
    "            pytorch_model=model,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=input_example,\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    # Return the metric to optimize\n",
    "    return mae\n",
    "\n",
    "# Create an Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best sMAPE:\", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
